<!DOCTYPE html>
<html class="client-nojs" lang="en" dir="ltr">
<head>
<meta charset="UTF-8"/>
<title>DALL-E - Wikipedia</title>
<script>document.documentElement.className="client-js";RLCONF={"wgBreakFrames":false,"wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgRequestId":"c7d88bac-84b5-4f87-b882-3fc4c528cede","wgCSPNonce":false,"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":false,"wgNamespaceNumber":0,"wgPageName":"DALL-E","wgTitle":"DALL-E","wgCurRevisionId":1068645284,"wgRevisionId":1068645284,"wgArticleId":66303034,"wgIsArticle":true,"wgIsRedirect":false,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["CS1 errors: missing periodical","Articles with short description","Short description is different from Wikidata","Applied machine learning","Artificial intelligence","Computational linguistics","Language modeling","Natural language generation","Natural language processing","Neural network software",
"Open-source artificial intelligence","Software using the MIT license","Unsupervised learning"],"wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgRelevantPageName":"DALL-E","wgRelevantArticleId":66303034,"wgIsProbablyEditable":true,"wgRelevantPageIsProbablyEditable":true,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgFlaggedRevsParams":{"tags":{"status":{"levels":-1}}},"wgVisualEditor":{"pageLanguageCode":"en","pageLanguageDir":"ltr","pageVariantFallbacks":"en"},"wgMFDisplayWikibaseDescriptions":{"search":true,"nearby":true,"watchlist":true,"tagline":false},"wgWMESchemaEditAttemptStepOversample":false,"wgWMEPageLength":30000,"wgNoticeProject":"wikipedia","wgMediaViewerOnClick":true,"wgMediaViewerEnabledByDefault":true,"wgPopupsFlags":10,"wgULSCurrentAutonym":"English","wgEditSubmitButtonLabelPublish":true,"wgCentralAuthMobileDomain":false,"wgULSPosition":"interlanguage","wgULSisCompactLinksEnabled":true,"wgWikibaseItemId":"Q105078662","wgGENewcomerTasksGuidanceEnabled":
true,"wgGEAskQuestionEnabled":false,"wgGELinkRecommendationsFrontendEnabled":false};RLSTATE={"ext.globalCssJs.user.styles":"ready","site.styles":"ready","user.styles":"ready","ext.globalCssJs.user":"ready","user":"ready","user.options":"loading","ext.cite.styles":"ready","skins.vector.styles.legacy":"ready","jquery.makeCollapsible.styles":"ready","ext.visualEditor.desktopArticleTarget.noscript":"ready","ext.wikimediaBadges":"ready","ext.uls.interlanguage":"ready","wikibase.client.init":"ready"};RLPAGEMODULES=["ext.cite.ux-enhancements","site","mediawiki.page.ready","jquery.makeCollapsible","mediawiki.toc","skins.vector.legacy.js","ext.gadget.ReferenceTooltips","ext.gadget.charinsert","ext.gadget.extra-toolbar-buttons","ext.gadget.refToolbar","ext.gadget.switcher","mmv.head","mmv.bootstrap.autostart","ext.visualEditor.desktopArticleTarget.init","ext.visualEditor.targetLoader","ext.eventLogging","ext.wikimediaEvents","ext.navigationTiming","ext.cx.eventlogging.campaigns",
"ext.centralNotice.geoIP","ext.centralNotice.startUp","ext.centralauth.centralautologin","ext.popups","ext.uls.compactlinks","ext.uls.interface","ext.growthExperiments.SuggestedEditSession"];</script>
<script>(RLQ=window.RLQ||[]).push(function(){mw.loader.implement("user.options@1i9g4",function($,jQuery,require,module){mw.user.tokens.set({"patrolToken":"+\\","watchToken":"+\\","csrfToken":"+\\"});});});</script>
<link rel="stylesheet" href="/w/load.php?lang=en&amp;modules=ext.cite.styles%7Cext.uls.interlanguage%7Cext.visualEditor.desktopArticleTarget.noscript%7Cext.wikimediaBadges%7Cjquery.makeCollapsible.styles%7Cskins.vector.styles.legacy%7Cwikibase.client.init&amp;only=styles&amp;skin=vector"/>
<script async="" src="/w/load.php?lang=en&amp;modules=startup&amp;only=scripts&amp;raw=1&amp;skin=vector"></script>
<meta name="ResourceLoaderDynamicStyles" content=""/>
<link rel="stylesheet" href="/w/load.php?lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector"/>
<meta name="generator" content="MediaWiki 1.38.0-wmf.21"/>
<meta name="referrer" content="origin"/>
<meta name="referrer" content="origin-when-crossorigin"/>
<meta name="referrer" content="origin-when-cross-origin"/>
<meta name="format-detection" content="telephone=no"/>
<meta property="og:image" content="https://upload.wikimedia.org/wikipedia/commons/a/a3/DALL-E_sample.png"/>
<meta property="og:image:width" content="1200"/>
<meta property="og:image:height" content="1442"/>
<meta property="og:image" content="https://upload.wikimedia.org/wikipedia/commons/a/a3/DALL-E_sample.png"/>
<meta property="og:image:width" content="800"/>
<meta property="og:image:height" content="961"/>
<meta property="og:image" content="https://upload.wikimedia.org/wikipedia/commons/thumb/a/a3/DALL-E_sample.png/640px-DALL-E_sample.png"/>
<meta property="og:image:width" content="640"/>
<meta property="og:image:height" content="769"/>
<meta property="og:title" content="DALL-E - Wikipedia"/>
<meta property="og:type" content="website"/>
<link rel="preconnect" href="//upload.wikimedia.org"/>
<link rel="alternate" media="only screen and (max-width: 720px)" href="//en.m.wikipedia.org/wiki/DALL-E"/>
<link rel="alternate" type="application/x-wiki" title="Edit this page" href="/w/index.php?title=DALL-E&amp;action=edit"/>
<link rel="apple-touch-icon" href="/static/apple-touch/wikipedia.png"/>
<link rel="shortcut icon" href="/static/favicon/wikipedia.ico"/>
<link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="Wikipedia (en)"/>
<link rel="EditURI" type="application/rsd+xml" href="//en.wikipedia.org/w/api.php?action=rsd"/>
<link rel="license" href="https://creativecommons.org/licenses/by-sa/3.0/"/>
<link rel="canonical" href="https://en.wikipedia.org/wiki/DALL-E"/>
<link rel="dns-prefetch" href="//meta.wikimedia.org" />
<link rel="dns-prefetch" href="//login.wikimedia.org"/>
</head>
<body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject mw-editable page-DALL-E rootpage-DALL-E skin-vector action-view skin-vector-legacy"><div id="mw-page-base" class="noprint"></div>
<div id="mw-head-base" class="noprint"></div>
<div id="content" class="mw-body" role="main">
	<a id="top"></a>
	<div id="siteNotice"><!-- CentralNotice --></div>
	<div class="mw-indicators">
	</div>
	<h1 id="firstHeading" class="firstHeading mw-first-heading">DALL-E</h1>
	<div id="bodyContent" class="vector-body">
		<div id="siteSub" class="noprint">From Wikipedia, the free encyclopedia</div>
		<div id="contentSub"></div>
		<div id="contentSub2"></div>
		
		<div id="jump-to-nav"></div>
		<a class="mw-jump-link" href="#mw-head">Jump to navigation</a>
		<a class="mw-jump-link" href="#searchInput">Jump to search</a>
		<div id="mw-content-text" class="mw-body-content mw-content-ltr" lang="en" dir="ltr"><div class="mw-parser-output"><div class="shortdescription nomobile noexcerpt noprint searchaux" style="display:none">Artificial intelligence image creation program</div>
<style data-mw-deduplicate="TemplateStyles:r1066479718">.mw-parser-output .infobox-subbox{padding:0;border:none;margin:-3px;width:auto;min-width:100%;font-size:100%;clear:none;float:none;background-color:transparent}.mw-parser-output .infobox-3cols-child{margin:auto}.mw-parser-output .infobox .navbar{font-size:100%}body.skin-minerva .mw-parser-output .infobox-header,body.skin-minerva .mw-parser-output .infobox-subheader,body.skin-minerva .mw-parser-output .infobox-above,body.skin-minerva .mw-parser-output .infobox-title,body.skin-minerva .mw-parser-output .infobox-image,body.skin-minerva .mw-parser-output .infobox-full-data,body.skin-minerva .mw-parser-output .infobox-below{text-align:center}</style><table class="infobox vevent"><caption class="infobox-title summary">DALL-E</caption><tbody><tr><td colspan="2" class="infobox-image"><a href="/wiki/File:DALL-E_sample.png" class="image"><img alt="DALL-E sample.png" src="//upload.wikimedia.org/wikipedia/commons/thumb/a/a3/DALL-E_sample.png/300px-DALL-E_sample.png" decoding="async" width="300" height="360" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/a/a3/DALL-E_sample.png/450px-DALL-E_sample.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/a/a3/DALL-E_sample.png/600px-DALL-E_sample.png 2x" data-file-width="725" data-file-height="871" /></a><div class="infobox-caption">Images produced by DALL-E when given the text prompt "a professional high quality illustration of a giraffe dragon chimera. a giraffe imitating a dragon. a giraffe made of dragon."</div></td></tr><tr><th scope="row" class="infobox-label" style="white-space: nowrap;"><a href="/wiki/Programmer" title="Programmer">Original author(s)</a></th><td class="infobox-data"><a href="/wiki/OpenAI" title="OpenAI">OpenAI</a></td></tr><tr><th scope="row" class="infobox-label" style="white-space: nowrap;">Initial release</th><td class="infobox-data">5 January 2021</td></tr><tr><th scope="row" class="infobox-label" style="white-space: nowrap;"><a href="/wiki/Software_categories#Categorization_approaches" title="Software categories">Type</a></th><td class="infobox-data"><a href="/wiki/Transformer_(machine_learning_model)" title="Transformer (machine learning model)">Transformer</a> <a href="/wiki/Language_model" title="Language model">language model</a></td></tr><tr><th scope="row" class="infobox-label" style="white-space: nowrap;">Website</th><td class="infobox-data"><span class="url"><a rel="nofollow" class="external text" href="https://www.openai.com/blog/dall-e/">www<wbr />.openai<wbr />.com<wbr />/blog<wbr />/dall-e<wbr />/</a></span></td></tr></tbody></table>
<style data-mw-deduplicate="TemplateStyles:r1045330069">.mw-parser-output .sidebar{width:22em;float:right;clear:right;margin:0.5em 0 1em 1em;background:#f8f9fa;border:1px solid #aaa;padding:0.2em;text-align:center;line-height:1.4em;font-size:88%;border-collapse:collapse;display:table}body.skin-minerva .mw-parser-output .sidebar{display:table!important;float:right!important;margin:0.5em 0 1em 1em!important}.mw-parser-output .sidebar-subgroup{width:100%;margin:0;border-spacing:0}.mw-parser-output .sidebar-left{float:left;clear:left;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-none{float:none;clear:both;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-outer-title{padding:0 0.4em 0.2em;font-size:125%;line-height:1.2em;font-weight:bold}.mw-parser-output .sidebar-top-image{padding:0.4em}.mw-parser-output .sidebar-top-caption,.mw-parser-output .sidebar-pretitle-with-top-image,.mw-parser-output .sidebar-caption{padding:0.2em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-pretitle{padding:0.4em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-title,.mw-parser-output .sidebar-title-with-pretitle{padding:0.2em 0.8em;font-size:145%;line-height:1.2em}.mw-parser-output .sidebar-title-with-pretitle{padding:0.1em 0.4em}.mw-parser-output .sidebar-image{padding:0.2em 0.4em 0.4em}.mw-parser-output .sidebar-heading{padding:0.1em 0.4em}.mw-parser-output .sidebar-content{padding:0 0.5em 0.4em}.mw-parser-output .sidebar-content-with-subgroup{padding:0.1em 0.4em 0.2em}.mw-parser-output .sidebar-above,.mw-parser-output .sidebar-below{padding:0.3em 0.8em;font-weight:bold}.mw-parser-output .sidebar-collapse .sidebar-above,.mw-parser-output .sidebar-collapse .sidebar-below{border-top:1px solid #aaa;border-bottom:1px solid #aaa}.mw-parser-output .sidebar-navbar{text-align:right;font-size:115%;padding:0 0.4em 0.4em}.mw-parser-output .sidebar-list-title{padding:0 0.4em;text-align:left;font-weight:bold;line-height:1.6em;font-size:105%}.mw-parser-output .sidebar-list-title-c{padding:0 0.4em;text-align:center;margin:0 3.3em}@media(max-width:720px){body.mediawiki .mw-parser-output .sidebar{width:100%!important;clear:both;float:none!important;margin-left:0!important;margin-right:0!important}}</style><table class="sidebar sidebar-collapse nomobile nowraplinks hlist"><tbody><tr><td class="sidebar-pretitle">Part of a series on</td></tr><tr><th class="sidebar-title-with-pretitle" style="font-weight:normal;background:#ddf;"><a href="/wiki/Outline_of_artificial_intelligence" title="Outline of artificial intelligence">Artificial intelligence</a></th></tr><tr><td class="sidebar-image"><div class="center"><div class="floatnone"><a href="/wiki/File:Anatomy-1751201_1280.png" class="image"><img alt="Anatomy-1751201 1280.png" src="//upload.wikimedia.org/wikipedia/commons/thumb/7/7a/Anatomy-1751201_1280.png/100px-Anatomy-1751201_1280.png" decoding="async" width="100" height="85" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/7/7a/Anatomy-1751201_1280.png/150px-Anatomy-1751201_1280.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/7/7a/Anatomy-1751201_1280.png/200px-Anatomy-1751201_1280.png 2x" data-file-width="1280" data-file-height="1088" /></a></div></div></td></tr><tr><td class="sidebar-content">
<div class="sidebar-list mw-collapsible mw-collapsed"><div class="sidebar-list-title" style="background:#ddd;;border-top:1px solid #aaa;text-align:center;"><a href="/wiki/Artificial_intelligence#Goals" title="Artificial intelligence">Major goals</a></div><div class="sidebar-list-content mw-collapsible-content">
<ul><li><a href="/wiki/Artificial_general_intelligence" title="Artificial general intelligence">Artificial general intelligence</a></li>
<li><a href="/wiki/Automated_planning_and_scheduling" title="Automated planning and scheduling">Planning</a></li>
<li><a href="/wiki/Computer_vision" title="Computer vision">Computer vision</a></li>
<li><a href="/wiki/General_game_playing" title="General game playing">General game playing</a></li>
<li><a href="/wiki/Knowledge_representation_and_reasoning" title="Knowledge representation and reasoning">Knowledge reasoning</a></li>
<li><a href="/wiki/Machine_learning" title="Machine learning">Machine learning</a></li>
<li><a href="/wiki/Natural_language_processing" title="Natural language processing">Natural language processing</a></li>
<li><a href="/wiki/Robotics" title="Robotics">Robotics</a></li></ul></div></div></td>
</tr><tr><td class="sidebar-content">
<div class="sidebar-list mw-collapsible mw-collapsed"><div class="sidebar-list-title" style="background:#ddd;;border-top:1px solid #aaa;text-align:center;">Approaches</div><div class="sidebar-list-content mw-collapsible-content">
<ul><li><a href="/wiki/Symbolic_artificial_intelligence" title="Symbolic artificial intelligence">Symbolic</a></li>
<li><a href="/wiki/Deep_learning" title="Deep learning">Deep learning</a></li>
<li><a href="/wiki/Bayesian_network" title="Bayesian network">Bayesian networks</a></li>
<li><a href="/wiki/Evolutionary_algorithm" title="Evolutionary algorithm">Evolutionary algorithms</a></li></ul></div></div></td>
</tr><tr><td class="sidebar-content">
<div class="sidebar-list mw-collapsible mw-collapsed"><div class="sidebar-list-title" style="background:#ddd;;border-top:1px solid #aaa;text-align:center;"><a href="/wiki/Philosophy_of_artificial_intelligence" title="Philosophy of artificial intelligence">Philosophy</a></div><div class="sidebar-list-content mw-collapsible-content">
<ul><li><a href="/wiki/Chinese_room" title="Chinese room">Chinese room</a></li>
<li><a href="/wiki/Friendly_artificial_intelligence" title="Friendly artificial intelligence">Friendly AI</a></li>
<li><a href="/wiki/AI_control_problem" class="mw-redirect" title="AI control problem">Control problem</a>/<a href="/wiki/AI_takeover" title="AI takeover">Takeover</a></li>
<li><a href="/wiki/Ethics_of_artificial_intelligence" title="Ethics of artificial intelligence">Ethics</a></li>
<li><a href="/wiki/Existential_risk_from_artificial_general_intelligence" title="Existential risk from artificial general intelligence">Existential risk</a></li>
<li><a href="/wiki/Turing_test" title="Turing test">Turing test</a></li></ul></div></div></td>
</tr><tr><td class="sidebar-content">
<div class="sidebar-list mw-collapsible mw-collapsed"><div class="sidebar-list-title" style="background:#ddd;;border-top:1px solid #aaa;text-align:center;"><a href="/wiki/History_of_artificial_intelligence" title="History of artificial intelligence">History</a></div><div class="sidebar-list-content mw-collapsible-content">
<ul><li><a href="/wiki/Timeline_of_artificial_intelligence" title="Timeline of artificial intelligence">Timeline</a></li>
<li><a href="/wiki/Progress_in_artificial_intelligence" title="Progress in artificial intelligence">Progress</a></li>
<li><a href="/wiki/AI_winter" title="AI winter">AI winter</a></li></ul></div></div></td>
</tr><tr><td class="sidebar-content">
<div class="sidebar-list mw-collapsible mw-collapsed"><div class="sidebar-list-title" style="background:#ddd;;border-top:1px solid #aaa;text-align:center;">Technology</div><div class="sidebar-list-content mw-collapsible-content">
<ul><li><a href="/wiki/Applications_of_artificial_intelligence" title="Applications of artificial intelligence">Applications</a></li>
<li><a href="/wiki/List_of_artificial_intelligence_projects" title="List of artificial intelligence projects">Projects</a></li>
<li><a href="/wiki/List_of_programming_languages_for_artificial_intelligence" title="List of programming languages for artificial intelligence">Programming languages</a></li></ul></div></div></td>
</tr><tr><td class="sidebar-content">
<div class="sidebar-list mw-collapsible mw-collapsed"><div class="sidebar-list-title" style="background:#ddd;;border-top:1px solid #aaa;text-align:center;">Glossary</div><div class="sidebar-list-content mw-collapsible-content">
<ul><li><a href="/wiki/Glossary_of_artificial_intelligence" title="Glossary of artificial intelligence">Glossary</a></li></ul></div></div></td>
</tr><tr><td class="sidebar-navbar"><style data-mw-deduplicate="TemplateStyles:r1063604349">.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:"[ "}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:" ]"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}</style><div class="navbar plainlinks hlist navbar-mini"><ul><li class="nv-view"><a href="/wiki/Template:Artificial_intelligence" title="Template:Artificial intelligence"><abbr title="View this template">v</abbr></a></li><li class="nv-talk"><a href="/wiki/Template_talk:Artificial_intelligence" title="Template talk:Artificial intelligence"><abbr title="Discuss this template">t</abbr></a></li><li class="nv-edit"><a class="external text" href="https://en.wikipedia.org/w/index.php?title=Template:Artificial_intelligence&amp;action=edit"><abbr title="Edit this template">e</abbr></a></li></ul></div></td></tr></tbody></table>
<p><b>DALL-E</b> (stylized <b>DALL·E</b>) is an <a href="/wiki/Artificial_intelligence" title="Artificial intelligence">artificial intelligence</a> program that creates images from textual descriptions, revealed by <a href="/wiki/OpenAI" title="OpenAI">OpenAI</a> on January 5, 2021.<sup id="cite_ref-mittr_1-0" class="reference"><a href="#cite_note-mittr-1">&#91;1&#93;</a></sup> It uses a 12-billion parameter<sup id="cite_ref-vb_2-0" class="reference"><a href="#cite_note-vb-2">&#91;2&#93;</a></sup> version of the <a href="/wiki/GPT-3" title="GPT-3">GPT-3</a> Transformer model to interpret <a href="/wiki/Natural_language" title="Natural language">natural language</a> inputs (such as "a green leather purse shaped like a pentagon" or "an <a href="/wiki/Isometric_view" class="mw-redirect" title="Isometric view">isometric view</a> of a sad <a href="/wiki/Capybara" title="Capybara">capybara</a>") and generate corresponding images.<sup id="cite_ref-tc_3-0" class="reference"><a href="#cite_note-tc-3">&#91;3&#93;</a></sup> It can create images of realistic objects ("a stained glass window with an image of a blue strawberry") as well as objects that do not exist in reality ("a cube with the texture of a porcupine").<sup id="cite_ref-vb2oped_4-0" class="reference"><a href="#cite_note-vb2oped-4">&#91;4&#93;</a></sup><sup id="cite_ref-zme_5-0" class="reference"><a href="#cite_note-zme-5">&#91;5&#93;</a></sup><sup id="cite_ref-axios_6-0" class="reference"><a href="#cite_note-axios-6">&#91;6&#93;</a></sup> Its name is a <a href="/wiki/Portmanteau" title="Portmanteau">portmanteau</a> of <i><a href="/wiki/WALL-E" title="WALL-E">WALL-E</a></i> and <a href="/wiki/Salvador_Dal%C3%AD" title="Salvador Dalí">Salvador Dalí</a>.<sup id="cite_ref-tc_3-1" class="reference"><a href="#cite_note-tc-3">&#91;3&#93;</a></sup><sup id="cite_ref-vb_2-1" class="reference"><a href="#cite_note-vb-2">&#91;2&#93;</a></sup> 
</p><p>Many <a href="/wiki/Neural_net" class="mw-redirect" title="Neural net">neural nets</a> from the 2000s onward have been able to generate realistic images.<sup id="cite_ref-tc_3-2" class="reference"><a href="#cite_note-tc-3">&#91;3&#93;</a></sup> DALL-E, however, is able to generate them from natural language prompts, which it "understands [...] and rarely fails in any serious way".<sup id="cite_ref-tc_3-3" class="reference"><a href="#cite_note-tc-3">&#91;3&#93;</a></sup>
</p><p>DALL-E was developed and announced to the public in conjunction with <b>CLIP (Contrastive Language-Image Pre-training)</b>,<sup id="cite_ref-mittr_1-1" class="reference"><a href="#cite_note-mittr-1">&#91;1&#93;</a></sup> a separate model whose role is to "understand and rank" its output.<sup id="cite_ref-tc_3-4" class="reference"><a href="#cite_note-tc-3">&#91;3&#93;</a></sup> The images that DALL-E generates are curated by CLIP, which presents the highest-quality images for any given prompt.<sup id="cite_ref-mittr_1-2" class="reference"><a href="#cite_note-mittr-1">&#91;1&#93;</a></sup> OpenAI has refused to release source code for either model; a "controlled demo" of DALL-E is available on OpenAI's website, where output from a limited selection of sample prompts can be viewed.<sup id="cite_ref-vb_2-2" class="reference"><a href="#cite_note-vb-2">&#91;2&#93;</a></sup> Open-source alternatives, trained on smaller amounts of data, like DALL-E Mini, have been released by communities.<sup id="cite_ref-7" class="reference"><a href="#cite_note-7">&#91;7&#93;</a></sup>
</p><p>According to <i><a href="/wiki/MIT_Technology_Review" title="MIT Technology Review">MIT Technology Review</a></i>, one of OpenAI's objectives was to "give language models a better grasp of the everyday concepts that humans use to make sense of things".<sup id="cite_ref-mittr_1-3" class="reference"><a href="#cite_note-mittr-1">&#91;1&#93;</a></sup>
</p>
<div id="toc" class="toc" role="navigation" aria-labelledby="mw-toc-heading"><input type="checkbox" role="button" id="toctogglecheckbox" class="toctogglecheckbox" style="display:none" /><div class="toctitle" lang="en" dir="ltr"><h2 id="mw-toc-heading">Contents</h2><span class="toctogglespan"><label class="toctogglelabel" for="toctogglecheckbox"></label></span></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#Architecture"><span class="tocnumber">1</span> <span class="toctext">Architecture</span></a></li>
<li class="toclevel-1 tocsection-2"><a href="#Performance"><span class="tocnumber">2</span> <span class="toctext">Performance</span></a>
<ul>
<li class="toclevel-2 tocsection-3"><a href="#Implications"><span class="tocnumber">2.1</span> <span class="toctext">Implications</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-4"><a href="#References"><span class="tocnumber">3</span> <span class="toctext">References</span></a></li>
</ul>
</div>

<h2><span class="mw-headline" id="Architecture">Architecture</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=DALL-E&amp;action=edit&amp;section=1" title="Edit section: Architecture">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<style data-mw-deduplicate="TemplateStyles:r1033289096">.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}</style><div role="note" class="hatnote navigation-not-searchable">Main article: <a href="/wiki/GPT-3" title="GPT-3">GPT-3</a></div>
<p>The <a href="/wiki/Generative_Pre-trained_Transformer" class="mw-redirect" title="Generative Pre-trained Transformer">Generative Pre-trained Transformer</a> (GPT) model was initially developed by OpenAI in 2018,<sup id="cite_ref-gpt1paper_8-0" class="reference"><a href="#cite_note-gpt1paper-8">&#91;8&#93;</a></sup> using the <a href="/wiki/Transformer_(machine_learning_model)" title="Transformer (machine learning model)">Transformer</a> architecture. The first iteration, GPT, was scaled up to produce <a href="/wiki/GPT-2" title="GPT-2">GPT-2</a> in 2019;<sup id="cite_ref-gpt2paper_9-0" class="reference"><a href="#cite_note-gpt2paper-9">&#91;9&#93;</a></sup> in 2020 it was scaled up again to produce <a href="/wiki/GPT-3" title="GPT-3">GPT-3</a>.<sup id="cite_ref-gpt3paper_10-0" class="reference"><a href="#cite_note-gpt3paper-10">&#91;10&#93;</a></sup><sup id="cite_ref-vb_2-3" class="reference"><a href="#cite_note-vb-2">&#91;2&#93;</a></sup><sup id="cite_ref-dallepaper_11-0" class="reference"><a href="#cite_note-dallepaper-11">&#91;11&#93;</a></sup>
</p><p>DALL-E's model is a multimodal implementation of GPT-3<sup id="cite_ref-impact_12-0" class="reference"><a href="#cite_note-impact-12">&#91;12&#93;</a></sup> with 12 billion parameters<sup id="cite_ref-vb_2-4" class="reference"><a href="#cite_note-vb-2">&#91;2&#93;</a></sup> (scaled down from GPT-3's 175 billion)<sup id="cite_ref-gpt3paper_10-1" class="reference"><a href="#cite_note-gpt3paper-10">&#91;10&#93;</a></sup> which "swaps text for pixels", trained on text-image pairs from the Internet.<sup id="cite_ref-mittr_1-4" class="reference"><a href="#cite_note-mittr-1">&#91;1&#93;</a></sup> It uses <a href="/wiki/Zero-shot_learning" title="Zero-shot learning">zero-shot learning</a> to generate output from a description and cue without further training.<sup id="cite_ref-engadget_13-0" class="reference"><a href="#cite_note-engadget-13">&#91;13&#93;</a></sup>
</p><p>DALL-E generates large amounts of images in response to prompts. Another OpenAI model, CLIP, was developed in conjunction (and announced simultaneously) with DALL-E to "understand and rank" this output.<sup id="cite_ref-tc_3-5" class="reference"><a href="#cite_note-tc-3">&#91;3&#93;</a></sup> CLIP was trained on over 400 million pairs of images and text.<sup id="cite_ref-vb_2-5" class="reference"><a href="#cite_note-vb-2">&#91;2&#93;</a></sup> CLIP is an image recognition system;<sup id="cite_ref-synced_14-0" class="reference"><a href="#cite_note-synced-14">&#91;14&#93;</a></sup> however, unlike most <a href="/wiki/Classifier_(machine_learning)" class="mw-redirect" title="Classifier (machine learning)">classifier</a> models, CLIP was not trained on curated datasets of labeled images (such as <a href="/wiki/ImageNet" title="ImageNet">ImageNet</a>), but instead on images and descriptions <a href="/wiki/Web_scraping" title="Web scraping">scraped</a> from the Internet.<sup id="cite_ref-mittr_1-5" class="reference"><a href="#cite_note-mittr-1">&#91;1&#93;</a></sup> Rather than learn from a single label, CLIP associates images with entire captions.<sup id="cite_ref-mittr_1-6" class="reference"><a href="#cite_note-mittr-1">&#91;1&#93;</a></sup> CLIP was trained to predict which caption (out of a "random selection" of 32,768 possible captions) was most appropriate for an image, allowing it to subsequently identify objects in a wide variety of images outside its training set.<sup id="cite_ref-mittr_1-7" class="reference"><a href="#cite_note-mittr-1">&#91;1&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="Performance">Performance</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=DALL-E&amp;action=edit&amp;section=2" title="Edit section: Performance">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>DALL-E is capable of generating imagery in a variety of styles, from <a href="/wiki/Photorealistic" class="mw-redirect" title="Photorealistic">photorealistic</a> imagery<sup id="cite_ref-vb_2-6" class="reference"><a href="#cite_note-vb-2">&#91;2&#93;</a></sup> to <a href="/wiki/Paintings" class="mw-redirect" title="Paintings">paintings</a> and <a href="/wiki/Emoji" title="Emoji">emoji</a>. It can also "manipulate and rearrange" objects in its images.<sup id="cite_ref-vb_2-7" class="reference"><a href="#cite_note-vb-2">&#91;2&#93;</a></sup> One ability noted by its creators was the correct placement of design elements in novel compositions without explicit instruction: "For example, when asked to draw a daikon radish blowing its nose, sipping a latte, or riding a unicycle, DALL·E often draws the kerchief, hands, and feet in plausible locations."<sup id="cite_ref-boing_15-0" class="reference"><a href="#cite_note-boing-15">&#91;15&#93;</a></sup>
</p><p>While DALL-E exhibited a wide variety of skills and abilities, on the release of its public demo, most coverage focused on a small subset of "surreal"<sup id="cite_ref-mittr_1-8" class="reference"><a href="#cite_note-mittr-1">&#91;1&#93;</a></sup> or "quirky"<sup id="cite_ref-cnbc_16-0" class="reference"><a href="#cite_note-cnbc-16">&#91;16&#93;</a></sup> output images. Specifically, DALL-E's output for "an illustration of a baby daikon radish in a tutu walking a dog" was mentioned in pieces from <i>Input</i>,<sup id="cite_ref-input_17-0" class="reference"><a href="#cite_note-input-17">&#91;17&#93;</a></sup> NBC,<sup id="cite_ref-nbc_18-0" class="reference"><a href="#cite_note-nbc-18">&#91;18&#93;</a></sup> <i>Nature</i>,<sup id="cite_ref-nature_19-0" class="reference"><a href="#cite_note-nature-19">&#91;19&#93;</a></sup> <i>VentureBeat</i>,<sup id="cite_ref-vb_2-8" class="reference"><a href="#cite_note-vb-2">&#91;2&#93;</a></sup> <i>Wired</i>,<sup id="cite_ref-wired_20-0" class="reference"><a href="#cite_note-wired-20">&#91;20&#93;</a></sup> CNN,<sup id="cite_ref-cnn_21-0" class="reference"><a href="#cite_note-cnn-21">&#91;21&#93;</a></sup> <i>New Scientist</i><sup id="cite_ref-newscientist_22-0" class="reference"><a href="#cite_note-newscientist-22">&#91;22&#93;</a></sup> and the BBC;<sup id="cite_ref-bbc_23-0" class="reference"><a href="#cite_note-bbc-23">&#91;23&#93;</a></sup> its output for "an armchair in the shape of an avocado" was reported on by <i>Wired</i>,<sup id="cite_ref-wired_20-1" class="reference"><a href="#cite_note-wired-20">&#91;20&#93;</a></sup> <i>VentureBeat</i>,<sup id="cite_ref-vb_2-9" class="reference"><a href="#cite_note-vb-2">&#91;2&#93;</a></sup> <i>New Scientist</i>,<sup id="cite_ref-newscientist_22-1" class="reference"><a href="#cite_note-newscientist-22">&#91;22&#93;</a></sup> NBC,<sup id="cite_ref-nbc_18-1" class="reference"><a href="#cite_note-nbc-18">&#91;18&#93;</a></sup> <i>MIT Technology Review</i>,<sup id="cite_ref-mittr_1-9" class="reference"><a href="#cite_note-mittr-1">&#91;1&#93;</a></sup> CNBC,<sup id="cite_ref-cnbc_16-1" class="reference"><a href="#cite_note-cnbc-16">&#91;16&#93;</a></sup> CNN<sup id="cite_ref-cnn_21-1" class="reference"><a href="#cite_note-cnn-21">&#91;21&#93;</a></sup> and the BBC.<sup id="cite_ref-bbc_23-1" class="reference"><a href="#cite_note-bbc-23">&#91;23&#93;</a></sup> In contrast, DALL-E's unintentional development of visual reasoning skills sufficient to solve <a href="/wiki/Raven%27s_Progressive_Matrices" title="Raven&#39;s Progressive Matrices">Raven's Matrices</a> (visual tests often administered to humans to measure intelligence) was reported on by machine learning engineer Dale Markowitz in a piece for <i>TheNextWeb</i>.<sup id="cite_ref-dale_24-0" class="reference"><a href="#cite_note-dale-24">&#91;24&#93;</a></sup>
</p><p><i><a href="/wiki/Nature_(journal)" title="Nature (journal)">Nature</a></i> introduced DALL-E as "an artificial-intelligence program that can draw pretty much anything you ask for".<sup id="cite_ref-nature_19-1" class="reference"><a href="#cite_note-nature-19">&#91;19&#93;</a></sup> <i><a href="/wiki/TheNextWeb" class="mw-redirect" title="TheNextWeb">TheNextWeb</a></i>'s Thomas Macaulay called its images "striking" and "seriously impressive", remarking on its ability to "create entirely new pictures by exploring the structure of a prompt — including fantastical objects combining unrelated ideas that it was never fed in training".<sup id="cite_ref-tnw_25-0" class="reference"><a href="#cite_note-tnw-25">&#91;25&#93;</a></sup> <i>ExtremeTech</i> said that "sometimes the renderings are little better than fingerpainting, but other times they’re startlingly accurate portrayals";<sup id="cite_ref-extreme_26-0" class="reference"><a href="#cite_note-extreme-26">&#91;26&#93;</a></sup> <i><a href="/wiki/TechCrunch" title="TechCrunch">TechCrunch</a></i> noted that, while DALL-E was "fabulously interesting and powerful work", it occasionally produced bizarre or incomprehensible output, and "many images it generates are more than a little… off":<sup id="cite_ref-tc_3-6" class="reference"><a href="#cite_note-tc-3">&#91;3&#93;</a></sup>
</p>
<blockquote><p>Saying “a green leather purse shaped like a pentagon” may produce what’s expected but “a blue suede purse shaped like a pentagon” might produce nightmare fuel. Why? It’s hard to say, given the black-box nature of these systems.<sup id="cite_ref-tc_3-7" class="reference"><a href="#cite_note-tc-3">&#91;3&#93;</a></sup></p></blockquote>
<p>Despite this, DALL-E was described as "remarkably robust to such changes" and reliable in producing images for a wide variety of arbitrary descriptions.<sup id="cite_ref-tc_3-8" class="reference"><a href="#cite_note-tc-3">&#91;3&#93;</a></sup> Sam Shead, reporting for <a href="/wiki/CNBC" title="CNBC">CNBC</a>, called its images "quirky" and quoted Neil Lawrence, a professor of machine learning at the <a href="/wiki/University_of_Cambridge" title="University of Cambridge">University of Cambridge</a>, who described it as an "inspirational demonstration of the capacity of these models to store information about our world and generalize in ways that humans find very natural". Shead also quoted Mark Riedl, an associate professor at the <a href="/wiki/Georgia_Tech" title="Georgia Tech">Georgia Tech</a> School of Interactive Computing, as saying that DALL-E's demonstration results showed that it was able to "coherently blend concepts", a key element of human <a href="/wiki/Creativity" title="Creativity">creativity</a>, and that "the DALL-E demo is remarkable for producing illustrations that are much more coherent than other Text2Image systems I’ve seen in the past few years."<sup id="cite_ref-cnbc_16-2" class="reference"><a href="#cite_note-cnbc-16">&#91;16&#93;</a></sup> Riedl was also quoted by the <a href="/wiki/British_Broadcasting_Corporation" class="mw-redirect" title="British Broadcasting Corporation">BBC</a> as saying that he was "impressed by what the system could do".<sup id="cite_ref-bbc_23-2" class="reference"><a href="#cite_note-bbc-23">&#91;23&#93;</a></sup> 
</p><p>DALL-E's ability to "fill in the blanks" and infer appropriate details without specific prompts was remarked on as well. <i>ExtremeTech</i> noted that a prompt to draw a penguin wearing a <a href="/wiki/Christmas_sweater" class="mw-redirect" title="Christmas sweater">Christmas sweater</a> produced images of penguins not also wearing sweaters, but also thematically related <a href="/wiki/Santa_hat" class="mw-redirect" title="Santa hat">Santa hats</a>,<sup id="cite_ref-extreme_26-1" class="reference"><a href="#cite_note-extreme-26">&#91;26&#93;</a></sup> and <i><a href="/wiki/Engadget" title="Engadget">Engadget</a></i> noted that appropriately-placed shadows appeared in output for the prompt "a painting of a fox sitting in a field during winter".<sup id="cite_ref-engadget_13-1" class="reference"><a href="#cite_note-engadget-13">&#91;13&#93;</a></sup> Furthermore, DALL-E exhibits broad understanding of visual and design trends; <i>ExtremeTech</i> said that "you can ask DALL-E for a picture of a phone or vacuum cleaner from a specified period of time, and it understands how those objects have changed".<sup id="cite_ref-extreme_26-2" class="reference"><a href="#cite_note-extreme-26">&#91;26&#93;</a></sup> <i>Engadget</i> also noted its unusual ability of "understanding how telephones and other objects change over time".<sup id="cite_ref-engadget_13-2" class="reference"><a href="#cite_note-engadget-13">&#91;13&#93;</a></sup> DALL-E has been described, along with other "narrow AI" like <a href="/wiki/AlphaGo" title="AlphaGo">AlphaGo</a>, <a href="/wiki/AlphaFold" title="AlphaFold">AlphaFold</a> and <a href="/wiki/GPT-3" title="GPT-3">GPT-3</a> as "[generating] interest in whether and how <a href="/wiki/Artificial_general_intelligence" title="Artificial general intelligence">artificial general intelligence</a> may be achieved".<sup id="cite_ref-replicators_27-0" class="reference"><a href="#cite_note-replicators-27">&#91;27&#93;</a></sup>
</p>
<h3><span class="mw-headline" id="Implications">Implications</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=DALL-E&amp;action=edit&amp;section=3" title="Edit section: Implications">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>OpenAI has refused to release the source code for DALL-E, or allow any use of it outside a small number of sample prompts;<sup id="cite_ref-vb_2-10" class="reference"><a href="#cite_note-vb-2">&#91;2&#93;</a></sup> OpenAI claimed that it planned to "analyze the societal impacts"<sup id="cite_ref-tnw_25-1" class="reference"><a href="#cite_note-tnw-25">&#91;25&#93;</a></sup> and "potential for bias" in models like DALL-E.<sup id="cite_ref-cnbc_16-3" class="reference"><a href="#cite_note-cnbc-16">&#91;16&#93;</a></sup> Despite the lack of access, at least one potential implication of DALL-E has been discussed, with several journalists and content writers mainly predicting that DALL-E could have effects on the field of journalism and content writing. Sam Shead's CNBC piece noted that some had concerns about the then-lack of a published paper describing the system, and that DALL-E had not been "opened sourced"&#32;&#91;<i><a href="/wiki/Sic" title="Sic">sic</a></i>&#93;.<sup id="cite_ref-cnbc_16-4" class="reference"><a href="#cite_note-cnbc-16">&#91;16&#93;</a></sup> 
</p><p>While <i>TechCrunch</i> said "don’t write stock photography and illustration’s obituaries just yet",<sup id="cite_ref-tc_3-9" class="reference"><a href="#cite_note-tc-3">&#91;3&#93;</a></sup> <i>Engadget</i> said that "if developed further, DALL-E has vast potential to disrupt fields like stock photography and illustration, with all the good and bad that entails".<sup id="cite_ref-engadget_13-3" class="reference"><a href="#cite_note-engadget-13">&#91;13&#93;</a></sup>
</p><p>In a <i><a href="/wiki/Forbes" title="Forbes">Forbes</a></i> opinion piece, <a href="/wiki/Venture_capitalist" class="mw-redirect" title="Venture capitalist">venture capitalist</a> Rob Toews said that DALL-E "presaged the dawn of a new AI paradigm known as <a href="/w/index.php?title=Multimodal_AI&amp;action=edit&amp;redlink=1" class="new" title="Multimodal AI (page does not exist)">multimodal AI</a>", in which systems would be capable of "interpreting, synthesizing and translating between multiple informational modalities"; he went on to say DALL-E demonstrated that "it is becoming harder and harder to deny that artificial intelligence is capable of creativity". Based on the sample prompts (which included clothed <a href="/wiki/Mannequin" title="Mannequin">mannequins</a> and items of furniture), he predicted that DALL-E might be used by <a href="/wiki/Fashion_designer" class="mw-redirect" title="Fashion designer">fashion designers</a> and <a href="/wiki/Furniture_designer" class="mw-redirect" title="Furniture designer">furniture designers</a>, but that "the technology is going to continue to improve rapidly".<sup id="cite_ref-forbesoped_28-0" class="reference"><a href="#cite_note-forbesoped-28">&#91;28&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=DALL-E&amp;action=edit&amp;section=4" title="Edit section: References">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div class="mw-references-wrap mw-references-columns"><ol class="references">
<li id="cite_note-mittr-1"><span class="mw-cite-backlink">^ <a href="#cite_ref-mittr_1-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-mittr_1-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-mittr_1-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-mittr_1-3"><sup><i><b>d</b></i></sup></a> <a href="#cite_ref-mittr_1-4"><sup><i><b>e</b></i></sup></a> <a href="#cite_ref-mittr_1-5"><sup><i><b>f</b></i></sup></a> <a href="#cite_ref-mittr_1-6"><sup><i><b>g</b></i></sup></a> <a href="#cite_ref-mittr_1-7"><sup><i><b>h</b></i></sup></a> <a href="#cite_ref-mittr_1-8"><sup><i><b>i</b></i></sup></a> <a href="#cite_ref-mittr_1-9"><sup><i><b>j</b></i></sup></a></span> <span class="reference-text"><style data-mw-deduplicate="TemplateStyles:r1067248974">.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}</style><cite id="CITEREFHeaven2021" class="citation web cs1">Heaven, Will Douglas (5 January 2021). <a rel="nofollow" class="external text" href="https://www.technologyreview.com/2021/01/05/1015754/avocado-armchair-future-ai-openai-deep-learning-nlp-gpt3-computer-vision-common-sense/">"This avocado armchair could be the future of AI"</a>. MIT Technology Review<span class="reference-accessdate">. Retrieved <span class="nowrap">5 January</span> 2021</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=This+avocado+armchair+could+be+the+future+of+AI&amp;rft.pub=MIT+Technology+Review&amp;rft.date=2021-01-05&amp;rft.aulast=Heaven&amp;rft.aufirst=Will+Douglas&amp;rft_id=https%3A%2F%2Fwww.technologyreview.com%2F2021%2F01%2F05%2F1015754%2Favocado-armchair-future-ai-openai-deep-learning-nlp-gpt3-computer-vision-common-sense%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ADALL-E" class="Z3988"></span></span>
</li>
<li id="cite_note-vb-2"><span class="mw-cite-backlink">^ <a href="#cite_ref-vb_2-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-vb_2-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-vb_2-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-vb_2-3"><sup><i><b>d</b></i></sup></a> <a href="#cite_ref-vb_2-4"><sup><i><b>e</b></i></sup></a> <a href="#cite_ref-vb_2-5"><sup><i><b>f</b></i></sup></a> <a href="#cite_ref-vb_2-6"><sup><i><b>g</b></i></sup></a> <a href="#cite_ref-vb_2-7"><sup><i><b>h</b></i></sup></a> <a href="#cite_ref-vb_2-8"><sup><i><b>i</b></i></sup></a> <a href="#cite_ref-vb_2-9"><sup><i><b>j</b></i></sup></a> <a href="#cite_ref-vb_2-10"><sup><i><b>k</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1067248974"/><cite id="CITEREFJohnson2021" class="citation web cs1">Johnson, Khari (5 January 2021). <a rel="nofollow" class="external text" href="https://venturebeat.com/2021/01/05/openai-debuts-dall-e-for-generating-images-from-text/">"OpenAI debuts DALL-E for generating images from text"</a>. VentureBeat. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20210105221534/https://venturebeat.com/2021/01/05/openai-debuts-dall-e-for-generating-images-from-text/">Archived</a> from the original on 5 January 2021<span class="reference-accessdate">. Retrieved <span class="nowrap">5 January</span> 2021</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=OpenAI+debuts+DALL-E+for+generating+images+from+text&amp;rft.pub=VentureBeat&amp;rft.date=2021-01-05&amp;rft.aulast=Johnson&amp;rft.aufirst=Khari&amp;rft_id=https%3A%2F%2Fventurebeat.com%2F2021%2F01%2F05%2Fopenai-debuts-dall-e-for-generating-images-from-text%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ADALL-E" class="Z3988"></span></span>
</li>
<li id="cite_note-tc-3"><span class="mw-cite-backlink">^ <a href="#cite_ref-tc_3-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-tc_3-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-tc_3-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-tc_3-3"><sup><i><b>d</b></i></sup></a> <a href="#cite_ref-tc_3-4"><sup><i><b>e</b></i></sup></a> <a href="#cite_ref-tc_3-5"><sup><i><b>f</b></i></sup></a> <a href="#cite_ref-tc_3-6"><sup><i><b>g</b></i></sup></a> <a href="#cite_ref-tc_3-7"><sup><i><b>h</b></i></sup></a> <a href="#cite_ref-tc_3-8"><sup><i><b>i</b></i></sup></a> <a href="#cite_ref-tc_3-9"><sup><i><b>j</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1067248974"/><cite id="CITEREFColdewey2021" class="citation web cs1">Coldewey, Devin (5 January 2021). <a rel="nofollow" class="external text" href="https://techcrunch.com/2021/01/05/openais-dall-e-creates-plausible-images-of-literally-anything-you-ask-it-to/">"OpenAI's DALL-E creates plausible images of literally anything you ask it to"</a>. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20210106075542/https://techcrunch.com/2021/01/05/openais-dall-e-creates-plausible-images-of-literally-anything-you-ask-it-to/">Archived</a> from the original on 6 January 2021<span class="reference-accessdate">. Retrieved <span class="nowrap">5 January</span> 2021</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=OpenAI%27s+DALL-E+creates+plausible+images+of+literally+anything+you+ask+it+to&amp;rft.date=2021-01-05&amp;rft.aulast=Coldewey&amp;rft.aufirst=Devin&amp;rft_id=https%3A%2F%2Ftechcrunch.com%2F2021%2F01%2F05%2Fopenais-dall-e-creates-plausible-images-of-literally-anything-you-ask-it-to%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ADALL-E" class="Z3988"></span></span>
</li>
<li id="cite_note-vb2oped-4"><span class="mw-cite-backlink"><b><a href="#cite_ref-vb2oped_4-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1067248974"/><cite id="CITEREFGrossman2021" class="citation web cs1">Grossman, Gary (16 January 2021). <a rel="nofollow" class="external text" href="https://venturebeat.com/2021/01/16/openais-text-to-image-engine-dall-e-is-a-powerful-visual-idea-generator/">"OpenAI's text-to-image engine, DALL-E, is a powerful visual idea generator"</a>. <a href="/wiki/VentureBeat" title="VentureBeat">VentureBeat</a>. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20210226200420/https://venturebeat.com/2021/01/16/openais-text-to-image-engine-dall-e-is-a-powerful-visual-idea-generator/">Archived</a> from the original on 26 February 2021<span class="reference-accessdate">. Retrieved <span class="nowrap">2 March</span> 2021</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=OpenAI%27s+text-to-image+engine%2C+DALL-E%2C+is+a+powerful+visual+idea+generator&amp;rft.pub=VentureBeat&amp;rft.date=2021-01-16&amp;rft.aulast=Grossman&amp;rft.aufirst=Gary&amp;rft_id=https%3A%2F%2Fventurebeat.com%2F2021%2F01%2F16%2Fopenais-text-to-image-engine-dall-e-is-a-powerful-visual-idea-generator%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ADALL-E" class="Z3988"></span></span>
</li>
<li id="cite_note-zme-5"><span class="mw-cite-backlink"><b><a href="#cite_ref-zme_5-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1067248974"/><cite id="CITEREFAndrei2021" class="citation web cs1">Andrei, Mihai (8 January 2021). <a rel="nofollow" class="external text" href="https://www.zmescience.com/research/technology/this-ai-module-can-create-stunning-images-out-of-any-text-input/">"This AI module can create stunning images out of any text input"</a>. ZME Science. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20210129033439/https://www.zmescience.com/research/technology/this-ai-module-can-create-stunning-images-out-of-any-text-input/">Archived</a> from the original on 29 January 2021<span class="reference-accessdate">. Retrieved <span class="nowrap">2 March</span> 2021</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=This+AI+module+can+create+stunning+images+out+of+any+text+input&amp;rft.pub=ZME+Science&amp;rft.date=2021-01-08&amp;rft.aulast=Andrei&amp;rft.aufirst=Mihai&amp;rft_id=https%3A%2F%2Fwww.zmescience.com%2Fresearch%2Ftechnology%2Fthis-ai-module-can-create-stunning-images-out-of-any-text-input%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ADALL-E" class="Z3988"></span></span>
</li>
<li id="cite_note-axios-6"><span class="mw-cite-backlink"><b><a href="#cite_ref-axios_6-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1067248974"/><cite id="CITEREFWalsh2021" class="citation web cs1">Walsh, Bryan (5 January 2021). <a rel="nofollow" class="external text" href="https://www.axios.com/openai-artificial-intelligence-model-images-dall-e-5c977633-81cd-450c-8ce5-a30e5f0e90e7.html">"A new AI model draws images from text"</a>. <a href="/wiki/Axios_(website)" title="Axios (website)">Axios</a><span class="reference-accessdate">. Retrieved <span class="nowrap">2 March</span> 2021</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=A+new+AI+model+draws+images+from+text&amp;rft.pub=Axios&amp;rft.date=2021-01-05&amp;rft.aulast=Walsh&amp;rft.aufirst=Bryan&amp;rft_id=https%3A%2F%2Fwww.axios.com%2Fopenai-artificial-intelligence-model-images-dall-e-5c977633-81cd-450c-8ce5-a30e5f0e90e7.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ADALL-E" class="Z3988"></span></span>
</li>
<li id="cite_note-7"><span class="mw-cite-backlink"><b><a href="#cite_ref-7">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1067248974"/><cite id="CITEREFDaymaPatilCuencaSaifullah2021" class="citation cs2">Dayma, Boris; Patil, Suraj; Cuenca, Pedro; Saifullah, Khalid; Abraham, Tanishq; Lê Khắc, Phúc; Melas, Luke; Ghosh, Ritobrata (2021), <a rel="nofollow" class="external text" href="https://github.com/borisdayma/dalle-mini"><i>DALL·E Mini</i></a>, <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.5281%2Fzenodo.5146400">10.5281/zenodo.5146400</a><span class="reference-accessdate">, retrieved <span class="nowrap">2021-11-29</span></span></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=DALL%C2%B7E+Mini&amp;rft.date=2021&amp;rft_id=info%3Adoi%2F10.5281%2Fzenodo.5146400&amp;rft.aulast=Dayma&amp;rft.aufirst=Boris&amp;rft.au=Patil%2C+Suraj&amp;rft.au=Cuenca%2C+Pedro&amp;rft.au=Saifullah%2C+Khalid&amp;rft.au=Abraham%2C+Tanishq&amp;rft.au=L%C3%AA+Kh%E1%BA%AFc%2C+Ph%C3%BAc&amp;rft.au=Melas%2C+Luke&amp;rft.au=Ghosh%2C+Ritobrata&amp;rft_id=https%3A%2F%2Fgithub.com%2Fborisdayma%2Fdalle-mini&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ADALL-E" class="Z3988"></span></span>
</li>
<li id="cite_note-gpt1paper-8"><span class="mw-cite-backlink"><b><a href="#cite_ref-gpt1paper_8-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1067248974"/><cite id="CITEREFRadfordNarasimhanSalimansSutskever2018" class="citation web cs1">Radford, Alec; Narasimhan, Karthik; Salimans, Tim; Sutskever, Ilya (11 June 2018). <a rel="nofollow" class="external text" href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf">"Improving Language Understanding by Generative Pre-Training"</a> <span class="cs1-format">(PDF)</span>. <a href="/wiki/OpenAI" title="OpenAI">OpenAI</a>. p.&#160;12. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20210126024542/https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf">Archived</a> <span class="cs1-format">(PDF)</span> from the original on 26 January 2021<span class="reference-accessdate">. Retrieved <span class="nowrap">23 January</span> 2021</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Improving+Language+Understanding+by+Generative+Pre-Training&amp;rft.pages=12&amp;rft.pub=OpenAI&amp;rft.date=2018-06-11&amp;rft.aulast=Radford&amp;rft.aufirst=Alec&amp;rft.au=Narasimhan%2C+Karthik&amp;rft.au=Salimans%2C+Tim&amp;rft.au=Sutskever%2C+Ilya&amp;rft_id=https%3A%2F%2Fcdn.openai.com%2Fresearch-covers%2Flanguage-unsupervised%2Flanguage_understanding_paper.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ADALL-E" class="Z3988"></span></span>
</li>
<li id="cite_note-gpt2paper-9"><span class="mw-cite-backlink"><b><a href="#cite_ref-gpt2paper_9-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1067248974"/><cite id="CITEREFRadfordWuChildLuan2019" class="citation journal cs1">Radford, Alec; Wu, Jeffrey; Child, Rewon; Luan, David; Amodei, Dario; Sutskever, Ilua (14 February 2019). <a rel="nofollow" class="external text" href="https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">"Language models are unsupervised multitask learners"</a> <span class="cs1-format">(PDF)</span>. <b>1</b> (8). <a rel="nofollow" class="external text" href="https://web.archive.org/web/20210206183945/https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">Archived</a> <span class="cs1-format">(PDF)</span> from the original on 6 February 2021<span class="reference-accessdate">. Retrieved <span class="nowrap">19 December</span> 2020</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Language+models+are+unsupervised+multitask+learners&amp;rft.volume=1&amp;rft.issue=8&amp;rft.date=2019-02-14&amp;rft.aulast=Radford&amp;rft.aufirst=Alec&amp;rft.au=Wu%2C+Jeffrey&amp;rft.au=Child%2C+Rewon&amp;rft.au=Luan%2C+David&amp;rft.au=Amodei%2C+Dario&amp;rft.au=Sutskever%2C+Ilua&amp;rft_id=https%3A%2F%2Fcdn.openai.com%2Fbetter-language-models%2Flanguage_models_are_unsupervised_multitask_learners.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ADALL-E" class="Z3988"></span> <span class="cs1-hidden-error citation-comment"><code class="cs1-code">{{<a href="/wiki/Template:Cite_journal" title="Template:Cite journal">cite journal</a>}}</code>: </span><span class="cs1-hidden-error citation-comment">Cite journal requires <code class="cs1-code">&#124;journal=</code> (<a href="/wiki/Help:CS1_errors#missing_periodical" title="Help:CS1 errors">help</a>)</span></span>
</li>
<li id="cite_note-gpt3paper-10"><span class="mw-cite-backlink">^ <a href="#cite_ref-gpt3paper_10-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-gpt3paper_10-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1067248974"/><cite id="CITEREFBrownMannRyderSubbiah2020" class="citation arxiv cs1">Brown, Tom B.; Mann, Benjamin; Ryder, Nick; Subbiah, Melanie; Kaplan, Jared; Dhariwal, Prafulla; Neelakantan, Arvind; Shyam, Pranav; Sastry, Girish; Askell, Amanda; Agarwal, Sandhini; Herbert-Voss, Ariel; Krueger, Gretchen; Henighan, Tom; Child, Rewon; Ramesh, Aditya; Ziegler, Daniel M.; Wu, Jeffrey; Winter, Clemens; Hesse, Christopher; Chen, Mark; Sigler, Eric; Litwin, Mateusz; Gray, Scott; Chess, Benjamin; Clark, Jack; Berner, Christopher; McCandlish, Sam; Radford, Alec; Sutskever, Ilya; Amodei, Dario (July 22, 2020). "Language Models are Few-Shot Learners". <a href="/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//arxiv.org/abs/2005.14165">2005.14165</a></span> [<a rel="nofollow" class="external text" href="//arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Language+Models+are+Few-Shot+Learners&amp;rft.date=2020-07-22&amp;rft_id=info%3Aarxiv%2F2005.14165&amp;rft.aulast=Brown&amp;rft.aufirst=Tom+B.&amp;rft.au=Mann%2C+Benjamin&amp;rft.au=Ryder%2C+Nick&amp;rft.au=Subbiah%2C+Melanie&amp;rft.au=Kaplan%2C+Jared&amp;rft.au=Dhariwal%2C+Prafulla&amp;rft.au=Neelakantan%2C+Arvind&amp;rft.au=Shyam%2C+Pranav&amp;rft.au=Sastry%2C+Girish&amp;rft.au=Askell%2C+Amanda&amp;rft.au=Agarwal%2C+Sandhini&amp;rft.au=Herbert-Voss%2C+Ariel&amp;rft.au=Krueger%2C+Gretchen&amp;rft.au=Henighan%2C+Tom&amp;rft.au=Child%2C+Rewon&amp;rft.au=Ramesh%2C+Aditya&amp;rft.au=Ziegler%2C+Daniel+M.&amp;rft.au=Wu%2C+Jeffrey&amp;rft.au=Winter%2C+Clemens&amp;rft.au=Hesse%2C+Christopher&amp;rft.au=Chen%2C+Mark&amp;rft.au=Sigler%2C+Eric&amp;rft.au=Litwin%2C+Mateusz&amp;rft.au=Gray%2C+Scott&amp;rft.au=Chess%2C+Benjamin&amp;rft.au=Clark%2C+Jack&amp;rft.au=Berner%2C+Christopher&amp;rft.au=McCandlish%2C+Sam&amp;rft.au=Radford%2C+Alec&amp;rft.au=Sutskever%2C+Ilya&amp;rft.au=Amodei%2C+Dario&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ADALL-E" class="Z3988"></span></span>
</li>
<li id="cite_note-dallepaper-11"><span class="mw-cite-backlink"><b><a href="#cite_ref-dallepaper_11-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1067248974"/><cite id="CITEREFRameshPavlovGohGray2021" class="citation arxiv cs1">Ramesh, Aditya; Pavlov, Mikhail; Goh, Gabriel; Gray, Scott; Voss, Chelsea; Radford, Alec; Chen, Mark; Sutskever, Ilya (24 February 2021). "Zero-Shot Text-to-Image Generation". <a href="/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//arxiv.org/abs/2101.12092">2101.12092</a></span> [<a rel="nofollow" class="external text" href="//arxiv.org/archive/cs.LG">cs.LG</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Zero-Shot+Text-to-Image+Generation&amp;rft.date=2021-02-24&amp;rft_id=info%3Aarxiv%2F2101.12092&amp;rft.aulast=Ramesh&amp;rft.aufirst=Aditya&amp;rft.au=Pavlov%2C+Mikhail&amp;rft.au=Goh%2C+Gabriel&amp;rft.au=Gray%2C+Scott&amp;rft.au=Voss%2C+Chelsea&amp;rft.au=Radford%2C+Alec&amp;rft.au=Chen%2C+Mark&amp;rft.au=Sutskever%2C+Ilya&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ADALL-E" class="Z3988"></span></span>
</li>
<li id="cite_note-impact-12"><span class="mw-cite-backlink"><b><a href="#cite_ref-impact_12-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1067248974"/><cite id="CITEREFTamkinBrundageClarkGanguli2021" class="citation arxiv cs1">Tamkin, Alex; Brundage, Miles; Clark, Jack; Ganguli, Deep (2021). "Understanding the Capabilities, Limitations, and Societal Impact of Large Language Models". <a href="/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//arxiv.org/abs/2102.02503">2102.02503</a></span> [<a rel="nofollow" class="external text" href="//arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Understanding+the+Capabilities%2C+Limitations%2C+and+Societal+Impact+of+Large+Language+Models&amp;rft.date=2021&amp;rft_id=info%3Aarxiv%2F2102.02503&amp;rft.aulast=Tamkin&amp;rft.aufirst=Alex&amp;rft.au=Brundage%2C+Miles&amp;rft.au=Clark%2C+Jack&amp;rft.au=Ganguli%2C+Deep&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ADALL-E" class="Z3988"></span></span>
</li>
<li id="cite_note-engadget-13"><span class="mw-cite-backlink">^ <a href="#cite_ref-engadget_13-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-engadget_13-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-engadget_13-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-engadget_13-3"><sup><i><b>d</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1067248974"/><cite id="CITEREFDent2021" class="citation web cs1">Dent, Steve (6 January 2021). <a rel="nofollow" class="external text" href="https://www.engadget.com/dall-e-ai-gpt-make-image-from-any-description-135535140.html">"OpenAI's DALL-E app generates images from just a description"</a>. <a href="/wiki/Engadget" title="Engadget">Engadget</a>. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20210127225652/https://www.engadget.com/dall-e-ai-gpt-make-image-from-any-description-135535140.html">Archived</a> from the original on 27 January 2021<span class="reference-accessdate">. Retrieved <span class="nowrap">2 March</span> 2021</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=OpenAI%27s+DALL-E+app+generates+images+from+just+a+description&amp;rft.pub=Engadget&amp;rft.date=2021-01-06&amp;rft.aulast=Dent&amp;rft.aufirst=Steve&amp;rft_id=https%3A%2F%2Fwww.engadget.com%2Fdall-e-ai-gpt-make-image-from-any-description-135535140.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ADALL-E" class="Z3988"></span></span>
</li>
<li id="cite_note-synced-14"><span class="mw-cite-backlink"><b><a href="#cite_ref-synced_14-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1067248974"/><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://syncedreview.com/2021/01/05/this-time-openais-gpt-3-generates-images-from-text/">"For Its Latest Trick, OpenAI's GPT-3 Generates Images From Text Captions"</a>. Synced. 5 January 2021. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20210106185429/https://syncedreview.com/2021/01/05/this-time-openais-gpt-3-generates-images-from-text/">Archived</a> from the original on 6 January 2021<span class="reference-accessdate">. Retrieved <span class="nowrap">2 March</span> 2021</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=For+Its+Latest+Trick%2C+OpenAI%27s+GPT-3+Generates+Images+From+Text+Captions&amp;rft.pub=Synced&amp;rft.date=2021-01-05&amp;rft_id=https%3A%2F%2Fsyncedreview.com%2F2021%2F01%2F05%2Fthis-time-openais-gpt-3-generates-images-from-text%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ADALL-E" class="Z3988"></span></span>
</li>
<li id="cite_note-boing-15"><span class="mw-cite-backlink"><b><a href="#cite_ref-boing_15-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1067248974"/><cite id="CITEREFDunn2021" class="citation web cs1">Dunn, Thom (10 February 2021). <a rel="nofollow" class="external text" href="https://boingboing.net/2021/02/10/this-ai-neural-network-transforms-text-captions-into-art-like-a-jellyfish-pikachu.html">"This AI neural network transforms text captions into art, like a jellyfish Pikachu"</a>. <a href="/wiki/BoingBoing" class="mw-redirect" title="BoingBoing">BoingBoing</a>. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20210222001459/https://boingboing.net/2021/02/10/this-ai-neural-network-transforms-text-captions-into-art-like-a-jellyfish-pikachu.html">Archived</a> from the original on 22 February 2021<span class="reference-accessdate">. Retrieved <span class="nowrap">2 March</span> 2021</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=This+AI+neural+network+transforms+text+captions+into+art%2C+like+a+jellyfish+Pikachu&amp;rft.pub=BoingBoing&amp;rft.date=2021-02-10&amp;rft.aulast=Dunn&amp;rft.aufirst=Thom&amp;rft_id=https%3A%2F%2Fboingboing.net%2F2021%2F02%2F10%2Fthis-ai-neural-network-transforms-text-captions-into-art-like-a-jellyfish-pikachu.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ADALL-E" class="Z3988"></span></span>
</li>
<li id="cite_note-cnbc-16"><span class="mw-cite-backlink">^ <a href="#cite_ref-cnbc_16-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-cnbc_16-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-cnbc_16-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-cnbc_16-3"><sup><i><b>d</b></i></sup></a> <a href="#cite_ref-cnbc_16-4"><sup><i><b>e</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1067248974"/><cite id="CITEREFShead2021" class="citation web cs1">Shead, Sam (8 January 2021). <a rel="nofollow" class="external text" href="https://www.cnbc.com/2021/01/08/openai-shows-off-dall-e-image-generator-after-gpt-3.html">"Why everyone is talking about an image generator released by an Elon Musk-backed A.I. lab"</a>. <a href="/wiki/CNBC" title="CNBC">CNBC</a><span class="reference-accessdate">. Retrieved <span class="nowrap">2 March</span> 2021</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Why+everyone+is+talking+about+an+image+generator+released+by+an+Elon+Musk-backed+A.I.+lab&amp;rft.pub=CNBC&amp;rft.date=2021-01-08&amp;rft.aulast=Shead&amp;rft.aufirst=Sam&amp;rft_id=https%3A%2F%2Fwww.cnbc.com%2F2021%2F01%2F08%2Fopenai-shows-off-dall-e-image-generator-after-gpt-3.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ADALL-E" class="Z3988"></span></span>
</li>
<li id="cite_note-input-17"><span class="mw-cite-backlink"><b><a href="#cite_ref-input_17-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1067248974"/><cite id="CITEREFKasana2021" class="citation web cs1">Kasana, Mehreen (7 January 2021). <a rel="nofollow" class="external text" href="https://www.inputmag.com/tech/dalle-takes-your-text-turns-it-into-surreal-captivating-art">"This AI turns text into surreal, suggestion-driven art"</a>. Input. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20210129211643/https://www.inputmag.com/tech/dalle-takes-your-text-turns-it-into-surreal-captivating-art">Archived</a> from the original on 29 January 2021<span class="reference-accessdate">. Retrieved <span class="nowrap">2 March</span> 2021</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=This+AI+turns+text+into+surreal%2C+suggestion-driven+art&amp;rft.pub=Input&amp;rft.date=2021-01-07&amp;rft.aulast=Kasana&amp;rft.aufirst=Mehreen&amp;rft_id=https%3A%2F%2Fwww.inputmag.com%2Ftech%2Fdalle-takes-your-text-turns-it-into-surreal-captivating-art&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ADALL-E" class="Z3988"></span></span>
</li>
<li id="cite_note-nbc-18"><span class="mw-cite-backlink">^ <a href="#cite_ref-nbc_18-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-nbc_18-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1067248974"/><cite id="CITEREFEhrenkranz2021" class="citation web cs1">Ehrenkranz, Melanie (27 January 2021). <a rel="nofollow" class="external text" href="https://www.nbcnews.com/tech/innovation/here-s-dall-e-algorithm-learned-draw-anything-you-tell-n1255834">"Here's DALL-E: An algorithm learned to draw anything you tell it"</a>. <a href="/wiki/NBC_News" title="NBC News">NBC News</a>. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20210220164655/https://www.nbcnews.com/tech/innovation/here-s-dall-e-algorithm-learned-draw-anything-you-tell-n1255834">Archived</a> from the original on 20 February 2021<span class="reference-accessdate">. Retrieved <span class="nowrap">2 March</span> 2021</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Here%27s+DALL-E%3A+An+algorithm+learned+to+draw+anything+you+tell+it&amp;rft.pub=NBC+News&amp;rft.date=2021-01-27&amp;rft.aulast=Ehrenkranz&amp;rft.aufirst=Melanie&amp;rft_id=https%3A%2F%2Fwww.nbcnews.com%2Ftech%2Finnovation%2Fhere-s-dall-e-algorithm-learned-draw-anything-you-tell-n1255834&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ADALL-E" class="Z3988"></span></span>
</li>
<li id="cite_note-nature-19"><span class="mw-cite-backlink">^ <a href="#cite_ref-nature_19-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-nature_19-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1067248974"/><cite id="CITEREFStove2021" class="citation web cs1">Stove, Emma (5 February 2021). <a rel="nofollow" class="external text" href="https://www.nature.com/immersive/d41586-021-00095-y/index.html">"Tardigrade circus and a tree of life — January's best science images"</a>. <a href="/wiki/Nature_(journal)" title="Nature (journal)">Nature</a>. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20210308032636/https://www.nature.com/immersive/d41586-021-00095-y/index.html">Archived</a> from the original on 8 March 2021<span class="reference-accessdate">. Retrieved <span class="nowrap">2 March</span> 2021</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Tardigrade+circus+and+a+tree+of+life+%E2%80%94+January%27s+best+science+images&amp;rft.pub=Nature&amp;rft.date=2021-02-05&amp;rft.aulast=Stove&amp;rft.aufirst=Emma&amp;rft_id=https%3A%2F%2Fwww.nature.com%2Fimmersive%2Fd41586-021-00095-y%2Findex.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ADALL-E" class="Z3988"></span></span>
</li>
<li id="cite_note-wired-20"><span class="mw-cite-backlink">^ <a href="#cite_ref-wired_20-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-wired_20-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1067248974"/><cite id="CITEREFKnight2021" class="citation web cs1">Knight, Will (26 January 2021). <a rel="nofollow" class="external text" href="https://www.wired.com/story/ai-go-art-steering-self-driving-car/">"This AI Could Go From 'Art' to Steering a Self-Driving Car"</a>. Wired. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20210221010223/https://www.wired.com/story/ai-go-art-steering-self-driving-car/">Archived</a> from the original on 21 February 2021<span class="reference-accessdate">. Retrieved <span class="nowrap">2 March</span> 2021</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=This+AI+Could+Go+From+%27Art%27+to+Steering+a+Self-Driving+Car&amp;rft.pub=Wired&amp;rft.date=2021-01-26&amp;rft.aulast=Knight&amp;rft.aufirst=Will&amp;rft_id=https%3A%2F%2Fwww.wired.com%2Fstory%2Fai-go-art-steering-self-driving-car%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ADALL-E" class="Z3988"></span></span>
</li>
<li id="cite_note-cnn-21"><span class="mw-cite-backlink">^ <a href="#cite_ref-cnn_21-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-cnn_21-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1067248974"/><cite id="CITEREFMetz2021" class="citation web cs1">Metz, Rachel (2 February 2021). <a rel="nofollow" class="external text" href="https://www.cnn.com/2021/01/08/tech/artificial-intelligence-openai-images-from-text/index.html">"A radish in a tutu walking a dog? This AI can draw it really well"</a>. CNN<span class="reference-accessdate">. Retrieved <span class="nowrap">2 March</span> 2021</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=A+radish+in+a+tutu+walking+a+dog%3F+This+AI+can+draw+it+really+well&amp;rft.pub=CNN&amp;rft.date=2021-02-02&amp;rft.aulast=Metz&amp;rft.aufirst=Rachel&amp;rft_id=https%3A%2F%2Fwww.cnn.com%2F2021%2F01%2F08%2Ftech%2Fartificial-intelligence-openai-images-from-text%2Findex.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ADALL-E" class="Z3988"></span></span>
</li>
<li id="cite_note-newscientist-22"><span class="mw-cite-backlink">^ <a href="#cite_ref-newscientist_22-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-newscientist_22-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1067248974"/><cite id="CITEREFStokel-Walker2021" class="citation web cs1">Stokel-Walker, Chris (5 January 2021). <a rel="nofollow" class="external text" href="https://www.newscientist.com/article/2264022-ai-illustrator-draws-imaginative-pictures-to-go-with-text-captions/">"AI illustrator draws imaginative pictures to go with text captions"</a>. <a href="/wiki/New_Scientist" title="New Scientist">New Scientist</a>. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20210128005947/https://www.newscientist.com/article/2264022-ai-illustrator-draws-imaginative-pictures-to-go-with-text-captions/">Archived</a> from the original on 28 January 2021<span class="reference-accessdate">. Retrieved <span class="nowrap">4 March</span> 2021</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=AI+illustrator+draws+imaginative+pictures+to+go+with+text+captions&amp;rft.pub=New+Scientist&amp;rft.date=2021-01-05&amp;rft.aulast=Stokel-Walker&amp;rft.aufirst=Chris&amp;rft_id=https%3A%2F%2Fwww.newscientist.com%2Farticle%2F2264022-ai-illustrator-draws-imaginative-pictures-to-go-with-text-captions%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ADALL-E" class="Z3988"></span></span>
</li>
<li id="cite_note-bbc-23"><span class="mw-cite-backlink">^ <a href="#cite_ref-bbc_23-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-bbc_23-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-bbc_23-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1067248974"/><cite id="CITEREFWakefield2021" class="citation web cs1">Wakefield, Jane (6 January 2021). <a rel="nofollow" class="external text" href="https://www.bbc.com/news/technology-55559463">"AI draws dog-walking baby radish in a tutu"</a>. <a href="/wiki/British_Broadcasting_Corporation" class="mw-redirect" title="British Broadcasting Corporation">British Broadcasting Corporation</a>. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20210302170623/https://www.bbc.com/news/technology-55559463">Archived</a> from the original on 2 March 2021<span class="reference-accessdate">. Retrieved <span class="nowrap">3 March</span> 2021</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=AI+draws+dog-walking+baby+radish+in+a+tutu&amp;rft.pub=British+Broadcasting+Corporation&amp;rft.date=2021-01-06&amp;rft.aulast=Wakefield&amp;rft.aufirst=Jane&amp;rft_id=https%3A%2F%2Fwww.bbc.com%2Fnews%2Ftechnology-55559463&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ADALL-E" class="Z3988"></span></span>
</li>
<li id="cite_note-dale-24"><span class="mw-cite-backlink"><b><a href="#cite_ref-dale_24-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1067248974"/><cite id="CITEREFMarkowitz2021" class="citation web cs1">Markowitz, Dale (10 January 2021). <a rel="nofollow" class="external text" href="https://thenextweb.com/neural/2021/01/10/heres-how-openais-magical-dall-e-generates-images-from-text-syndication/">"Here's how OpenAI's magical DALL-E image generator works"</a>. <a href="/wiki/TheNextWeb" class="mw-redirect" title="TheNextWeb">TheNextWeb</a>. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20210223162340/https://thenextweb.com/neural/2021/01/10/heres-how-openais-magical-dall-e-generates-images-from-text-syndication/">Archived</a> from the original on 23 February 2021<span class="reference-accessdate">. Retrieved <span class="nowrap">2 March</span> 2021</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Here%27s+how+OpenAI%27s+magical+DALL-E+image+generator+works&amp;rft.pub=TheNextWeb&amp;rft.date=2021-01-10&amp;rft.aulast=Markowitz&amp;rft.aufirst=Dale&amp;rft_id=https%3A%2F%2Fthenextweb.com%2Fneural%2F2021%2F01%2F10%2Fheres-how-openais-magical-dall-e-generates-images-from-text-syndication%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ADALL-E" class="Z3988"></span></span>
</li>
<li id="cite_note-tnw-25"><span class="mw-cite-backlink">^ <a href="#cite_ref-tnw_25-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-tnw_25-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1067248974"/><cite id="CITEREFMacaulay2021" class="citation web cs1">Macaulay, Thomas (6 January 2021). <a rel="nofollow" class="external text" href="https://thenextweb.com/neural/2021/01/06/say-hello-to-openais-dall-e-a-gpt-3-powered-bot-that-creates-weird-images-from-text/">"Say hello to OpenAI's DALL-E, a GPT-3-powered bot that creates weird images from text"</a>. <a href="/wiki/TheNextWeb" class="mw-redirect" title="TheNextWeb">TheNextWeb</a>. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20210128034743/https://thenextweb.com/neural/2021/01/06/say-hello-to-openais-dall-e-a-gpt-3-powered-bot-that-creates-weird-images-from-text/">Archived</a> from the original on 28 January 2021<span class="reference-accessdate">. Retrieved <span class="nowrap">2 March</span> 2021</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Say+hello+to+OpenAI%27s+DALL-E%2C+a+GPT-3-powered+bot+that+creates+weird+images+from+text&amp;rft.pub=TheNextWeb&amp;rft.date=2021-01-06&amp;rft.aulast=Macaulay&amp;rft.aufirst=Thomas&amp;rft_id=https%3A%2F%2Fthenextweb.com%2Fneural%2F2021%2F01%2F06%2Fsay-hello-to-openais-dall-e-a-gpt-3-powered-bot-that-creates-weird-images-from-text%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ADALL-E" class="Z3988"></span></span>
</li>
<li id="cite_note-extreme-26"><span class="mw-cite-backlink">^ <a href="#cite_ref-extreme_26-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-extreme_26-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-extreme_26-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1067248974"/><cite id="CITEREFWhitwam2021" class="citation web cs1">Whitwam, Ryan (6 January 2021). <a rel="nofollow" class="external text" href="https://www.extremetech.com/extreme/318881-openais-dall-e-generates-images-from-text-descriptions">"OpenAI's 'DALL-E' Generates Images From Text Descriptions"</a>. ExtremeTech. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20210128064428/https://www.extremetech.com/extreme/318881-openais-dall-e-generates-images-from-text-descriptions">Archived</a> from the original on 28 January 2021<span class="reference-accessdate">. Retrieved <span class="nowrap">2 March</span> 2021</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=OpenAI%27s+%27DALL-E%27+Generates+Images+From+Text+Descriptions&amp;rft.pub=ExtremeTech&amp;rft.date=2021-01-06&amp;rft.aulast=Whitwam&amp;rft.aufirst=Ryan&amp;rft_id=https%3A%2F%2Fwww.extremetech.com%2Fextreme%2F318881-openais-dall-e-generates-images-from-text-descriptions&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ADALL-E" class="Z3988"></span></span>
</li>
<li id="cite_note-replicators-27"><span class="mw-cite-backlink"><b><a href="#cite_ref-replicators_27-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1067248974"/><cite id="CITEREFNichele2021" class="citation journal cs1">Nichele, Stefano (2021). <a rel="nofollow" class="external text" href="https://doi.org/10.1007%2Fs10710-021-09398-5">"Tim Taylor and Alan Dorin: Rise of the self-replicators—early visions of machines, AI and robots that can reproduce and evolve"</a>. <i>Genetic Programming and Evolvable Machines</i>. <b>22</b>: 141–145. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://doi.org/10.1007%2Fs10710-021-09398-5">10.1007/s10710-021-09398-5</a></span>. <a href="/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:231930573">231930573</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Genetic+Programming+and+Evolvable+Machines&amp;rft.atitle=Tim+Taylor+and+Alan+Dorin%3A+Rise+of+the+self-replicators%E2%80%94early+visions+of+machines%2C+AI+and+robots+that+can+reproduce+and+evolve&amp;rft.volume=22&amp;rft.pages=141-145&amp;rft.date=2021&amp;rft_id=info%3Adoi%2F10.1007%2Fs10710-021-09398-5&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A231930573%23id-name%3DS2CID&amp;rft.aulast=Nichele&amp;rft.aufirst=Stefano&amp;rft_id=%2F%2Fdoi.org%2F10.1007%252Fs10710-021-09398-5&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ADALL-E" class="Z3988"></span></span>
</li>
<li id="cite_note-forbesoped-28"><span class="mw-cite-backlink"><b><a href="#cite_ref-forbesoped_28-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1067248974"/><cite id="CITEREFToews2021" class="citation web cs1">Toews, Rob (18 January 2021). <a rel="nofollow" class="external text" href="https://www.forbes.com/sites/robtoews/2021/01/18/ai-and-creativity-why-openais-latest-model-is-a-big-deal/">"AI And Creativity: Why OpenAI's Latest Model Matters"</a>. <i><a href="/wiki/Forbes" title="Forbes">Forbes</a></i>. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20210212183950/https://www.forbes.com/sites/robtoews/2021/01/18/ai-and-creativity-why-openais-latest-model-is-a-big-deal/">Archived</a> from the original on 12 February 2021<span class="reference-accessdate">. Retrieved <span class="nowrap">2 March</span> 2021</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Forbes&amp;rft.atitle=AI+And+Creativity%3A+Why+OpenAI%27s+Latest+Model+Matters&amp;rft.date=2021-01-18&amp;rft.aulast=Toews&amp;rft.aufirst=Rob&amp;rft_id=https%3A%2F%2Fwww.forbes.com%2Fsites%2Frobtoews%2F2021%2F01%2F18%2Fai-and-creativity-why-openais-latest-model-is-a-big-deal%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ADALL-E" class="Z3988"></span></span>
</li>
</ol></div>
<div class="navbox-styles nomobile"><style data-mw-deduplicate="TemplateStyles:r1061467846">.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff}.mw-parser-output .navbox-even{background-color:#f7f7f7}.mw-parser-output .navbox-odd{background-color:transparent}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}</style></div><div role="navigation" class="navbox" aria-labelledby="Differentiable_computing" style="padding:3px"><table class="nowraplinks hlist mw-collapsible autocollapse navbox-inner" style="border-spacing:0;background:transparent;color:inherit"><tbody><tr><th scope="col" class="navbox-title" colspan="2"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1063604349"/><div class="navbar plainlinks hlist navbar-mini"><ul><li class="nv-view"><a href="/wiki/Template:Differentiable_computing" title="Template:Differentiable computing"><abbr title="View this template" style=";;background:none transparent;border:none;box-shadow:none;padding:0;">v</abbr></a></li><li class="nv-talk"><a href="/wiki/Template_talk:Differentiable_computing" title="Template talk:Differentiable computing"><abbr title="Discuss this template" style=";;background:none transparent;border:none;box-shadow:none;padding:0;">t</abbr></a></li><li class="nv-edit"><a class="external text" href="https://en.wikipedia.org/w/index.php?title=Template:Differentiable_computing&amp;action=edit"><abbr title="Edit this template" style=";;background:none transparent;border:none;box-shadow:none;padding:0;">e</abbr></a></li></ul></div><div id="Differentiable_computing" style="font-size:114%;margin:0 4em">Differentiable computing</div></th></tr><tr><th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Differentiable_function" title="Differentiable function">General</a></th><td class="navbox-list-with-group navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Differentiable_programming" title="Differentiable programming">Differentiable programming</a></li>
<li><a href="/wiki/Neural_Turing_machine" title="Neural Turing machine">Neural Turing machine</a></li>
<li><a href="/wiki/Differentiable_neural_computer" title="Differentiable neural computer">Differentiable neural computer</a></li>
<li><a href="/wiki/Automatic_differentiation" title="Automatic differentiation">Automatic differentiation</a></li>
<li><a href="/wiki/Neuromorphic_engineering" title="Neuromorphic engineering">Neuromorphic engineering</a></li>
<li><a href="/wiki/Cable_theory" title="Cable theory">Cable theory</a></li>
<li><a href="/wiki/Pattern_recognition" title="Pattern recognition">Pattern recognition</a></li>
<li><a href="/wiki/Computational_learning_theory" title="Computational learning theory">Computational learning theory</a></li>
<li><a href="/wiki/Tensor_calculus" title="Tensor calculus">Tensor calculus</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%">Concepts</th><td class="navbox-list-with-group navbox-list navbox-even" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Gradient_descent" title="Gradient descent">Gradient descent</a>
<ul><li><a href="/wiki/Stochastic_gradient_descent" title="Stochastic gradient descent">SGD</a></li></ul></li>
<li><a href="/wiki/Cluster_analysis" title="Cluster analysis">Clustering</a></li>
<li><a href="/wiki/Regression_analysis" title="Regression analysis">Regression</a>
<ul><li><a href="/wiki/Overfitting" title="Overfitting">Overfitting</a></li></ul></li>
<li><a href="/wiki/Adversarial_machine_learning" title="Adversarial machine learning">Adversary</a></li>
<li><a href="/wiki/Attention_(machine_learning)" title="Attention (machine learning)">Attention</a></li>
<li><a href="/wiki/Convolution" title="Convolution">Convolution</a></li>
<li><a href="/wiki/Loss_functions_for_classification" title="Loss functions for classification">Loss functions</a></li>
<li><a href="/wiki/Backpropagation" title="Backpropagation">Backpropagation</a></li>
<li><a href="/wiki/Batch_normalization" title="Batch normalization">Normalization</a></li>
<li><a href="/wiki/Activation_function" title="Activation function">Activation</a>
<ul><li><a href="/wiki/Softmax_function" title="Softmax function">Softmax</a></li>
<li><a href="/wiki/Sigmoid_function" title="Sigmoid function">Sigmoid</a></li>
<li><a href="/wiki/Rectifier_(neural_networks)" title="Rectifier (neural networks)">Rectifier</a></li></ul></li>
<li><a href="/wiki/Regularization_(mathematics)" title="Regularization (mathematics)">Regularization</a></li>
<li><a href="/wiki/Training,_validation,_and_test_sets" title="Training, validation, and test sets">Datasets</a>
<ul><li><a href="/wiki/Data_augmentation" title="Data augmentation">Augmentation</a></li></ul></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%">Programming languages</th><td class="navbox-list-with-group navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Python_(programming_language)" title="Python (programming language)">Python</a></li>
<li><a href="/wiki/Julia_(programming_language)" title="Julia (programming language)">Julia</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%">Application</th><td class="navbox-list-with-group navbox-list navbox-even" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Machine_learning" title="Machine learning">Machine learning</a></li>
<li><a href="/wiki/Artificial_neural_network" title="Artificial neural network">Artificial neural network</a>
<ul><li><a href="/wiki/Deep_learning" title="Deep learning">Deep learning</a></li></ul></li>
<li><a href="/wiki/Computational_science" title="Computational science">Scientific computing</a></li>
<li><a href="/wiki/Artificial_intelligence" title="Artificial intelligence">Artificial Intelligence</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%">Hardware</th><td class="navbox-list-with-group navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Graphcore" title="Graphcore">IPU</a></li>
<li><a href="/wiki/Tensor_Processing_Unit" title="Tensor Processing Unit">TPU</a></li>
<li><a href="/wiki/Vision_processing_unit" title="Vision processing unit">VPU</a></li>
<li><a href="/wiki/Memristor" title="Memristor">Memristor</a></li>
<li><a href="/wiki/SpiNNaker" title="SpiNNaker">SpiNNaker</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%">Software library</th><td class="navbox-list-with-group navbox-list navbox-even" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/TensorFlow" title="TensorFlow">TensorFlow</a></li>
<li><a href="/wiki/PyTorch" title="PyTorch">PyTorch</a></li>
<li><a href="/wiki/Keras" title="Keras">Keras</a></li>
<li><a href="/wiki/Theano_(software)" title="Theano (software)">Theano</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%">Implementation</th><td class="navbox-list-with-group navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em"></div><table class="nowraplinks navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="row" class="navbox-group" style="width:1%">Audio-visual</th><td class="navbox-list-with-group navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/AlexNet" title="AlexNet">AlexNet</a></li>
<li><a href="/wiki/WaveNet" title="WaveNet">WaveNet</a></li>
<li><a href="/wiki/Human_image_synthesis" title="Human image synthesis">Human image synthesis</a></li>
<li><a href="/wiki/Handwriting_recognition" title="Handwriting recognition">HWR</a></li>
<li><a href="/wiki/Optical_character_recognition" title="Optical character recognition">OCR</a></li>
<li><a href="/wiki/Speech_synthesis" title="Speech synthesis">Speech synthesis</a></li>
<li><a href="/wiki/Speech_recognition" title="Speech recognition">Speech recognition</a></li>
<li><a href="/wiki/Facial_recognition_system" title="Facial recognition system">Facial recognition</a></li>
<li><a href="/wiki/AlphaFold" title="AlphaFold">AlphaFold</a></li>
<li><a class="mw-selflink selflink">DALL-E</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%">Verbal</th><td class="navbox-list-with-group navbox-list navbox-even" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Word2vec" title="Word2vec">Word2vec</a></li>
<li><a href="/wiki/Transformer_(machine_learning_model)" title="Transformer (machine learning model)">Transformer</a></li>
<li><a href="/wiki/BERT_(language_model)" title="BERT (language model)">BERT</a></li>
<li><a href="/wiki/Neural_machine_translation" title="Neural machine translation">NMT</a></li>
<li><a href="/wiki/Project_Debater" title="Project Debater">Project Debater</a></li>
<li><a href="/wiki/Watson_(computer)" title="Watson (computer)">Watson</a></li>
<li><a href="/wiki/GPT-2" title="GPT-2">GPT-2</a></li>
<li><a href="/wiki/GPT-3" title="GPT-3">GPT-3</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%">Decisional</th><td class="navbox-list-with-group navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/AlphaGo" title="AlphaGo">AlphaGo</a></li>
<li><a href="/wiki/AlphaZero" title="AlphaZero">AlphaZero</a></li>
<li><a href="/wiki/Q-learning" title="Q-learning">Q-learning</a></li>
<li><a href="/wiki/State%E2%80%93action%E2%80%93reward%E2%80%93state%E2%80%93action" title="State–action–reward–state–action">SARSA</a></li>
<li><a href="/wiki/OpenAI_Five" title="OpenAI Five">OpenAI Five</a></li>
<li><a href="/wiki/Self-driving_car" title="Self-driving car">Self-driving car</a></li>
<li><a href="/wiki/MuZero" title="MuZero">MuZero</a></li>
<li><a href="/wiki/Action_selection" title="Action selection">Action selection</a></li>
<li><a href="/wiki/Robot_control" title="Robot control">Robot control</a></li></ul>
</div></td></tr></tbody></table><div></div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%">People</th><td class="navbox-list-with-group navbox-list navbox-even" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Alex_Graves_(computer_scientist)" title="Alex Graves (computer scientist)">Alex Graves</a></li>
<li><a href="/wiki/Ian_Goodfellow" title="Ian Goodfellow">Ian Goodfellow</a></li>
<li><a href="/wiki/Yoshua_Bengio" title="Yoshua Bengio">Yoshua Bengio</a></li>
<li><a href="/wiki/Geoffrey_Hinton" title="Geoffrey Hinton">Geoffrey Hinton</a></li>
<li><a href="/wiki/Yann_LeCun" title="Yann LeCun">Yann LeCun</a></li>
<li><a href="/wiki/Andrew_Ng" title="Andrew Ng">Andrew Ng</a></li>
<li><a href="/wiki/Demis_Hassabis" title="Demis Hassabis">Demis Hassabis</a></li>
<li><a href="/wiki/David_Silver_(computer_scientist)" title="David Silver (computer scientist)">David Silver</a></li>
<li><a href="/wiki/Fei-Fei_Li" title="Fei-Fei Li">Fei-Fei Li</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%">Organizations</th><td class="navbox-list-with-group navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/DeepMind" title="DeepMind">DeepMind</a></li>
<li><a href="/wiki/OpenAI" title="OpenAI">OpenAI</a></li>
<li><a href="/wiki/MIT_Computer_Science_and_Artificial_Intelligence_Laboratory" title="MIT Computer Science and Artificial Intelligence Laboratory">MIT CSAIL</a></li>
<li><a href="/wiki/Mila_(research_institute)" title="Mila (research institute)">Mila</a></li>
<li><a href="/wiki/Google_Brain" title="Google Brain">Google Brain</a></li>
<li><a href="https://fr.wikipedia.org/wiki/Facebook_Artificial_Intelligence_Research" class="extiw" title="fr:Facebook Artificial Intelligence Research">FAIR</a></li></ul>
</div></td></tr><tr><td class="navbox-abovebelow" colspan="2"><div>
<ul><li><a href="/wiki/File:Symbol_portal_class.svg" class="image" title="Portal"><img alt="" src="//upload.wikimedia.org/wikipedia/en/thumb/e/e2/Symbol_portal_class.svg/16px-Symbol_portal_class.svg.png" decoding="async" width="16" height="16" class="noviewer" srcset="//upload.wikimedia.org/wikipedia/en/thumb/e/e2/Symbol_portal_class.svg/23px-Symbol_portal_class.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/e/e2/Symbol_portal_class.svg/31px-Symbol_portal_class.svg.png 2x" data-file-width="180" data-file-height="185" /></a> Portals
<ul><li><a href="/wiki/Portal:Computer_programming" title="Portal:Computer programming">Computer programming</a></li>
<li><a href="/wiki/Portal:Technology" title="Portal:Technology">Technology</a></li></ul></li>
<li><img alt="" src="//upload.wikimedia.org/wikipedia/en/thumb/9/96/Symbol_category_class.svg/16px-Symbol_category_class.svg.png" decoding="async" title="Category" width="16" height="16" class="noviewer" srcset="//upload.wikimedia.org/wikipedia/en/thumb/9/96/Symbol_category_class.svg/23px-Symbol_category_class.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/9/96/Symbol_category_class.svg/31px-Symbol_category_class.svg.png 2x" data-file-width="180" data-file-height="185" /> Category
<ul><li><a href="/wiki/Category:Artificial_neural_networks" title="Category:Artificial neural networks">Artificial neural networks</a></li>
<li><a href="/wiki/Category:Machine_learning" title="Category:Machine learning">Machine learning</a></li></ul></li></ul>
</div></td></tr></tbody></table></div>
<!-- 
NewPP limit report
Parsed by mw1403
Cached time: 20220212190319
Cache expiry: 1814400
Reduced expiry: false
Complications: [vary‐revision‐sha1]
CPU time usage: 0.615 seconds
Real time usage: 0.728 seconds
Preprocessor visited node count: 2746/1000000
Post‐expand include size: 104353/2097152 bytes
Template argument size: 1554/2097152 bytes
Highest expansion depth: 13/100
Expensive parser function count: 3/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 105789/5000000 bytes
Lua time usage: 0.375/10.000 seconds
Lua memory usage: 7098581/52428800 bytes
Number of Wikibase entities loaded: 1/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  630.556      1 -total
 30.85%  194.540     22 Template:Cite_web
 12.47%   78.604      1 Template:Artificial_intelligence
 12.04%   75.914      1 Template:Sidebar_with_collapsible_lists
 11.00%   69.388      1 Template:Infobox_software
 10.12%   63.803      1 Template:Infobox
  9.47%   59.726      1 Template:Short_description
  9.37%   59.087      1 Template:Differentiable_computing
  9.34%   58.924      2 Template:Navbox
  5.66%   35.682      3 Template:Cite_arXiv
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:66303034-0!canonical and timestamp 20220212190319 and revision id 1068645284. Serialized with JSON.
 -->
</div><noscript><img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" /></noscript>
<div class="printfooter">Retrieved from "<a dir="ltr" href="https://en.wikipedia.org/w/index.php?title=DALL-E&amp;oldid=1068645284">https://en.wikipedia.org/w/index.php?title=DALL-E&amp;oldid=1068645284</a>"</div></div>
		<div id="catlinks" class="catlinks" data-mw="interface"><div id="mw-normal-catlinks" class="mw-normal-catlinks"><a href="/wiki/Help:Category" title="Help:Category">Categories</a>: <ul><li><a href="/wiki/Category:Applied_machine_learning" title="Category:Applied machine learning">Applied machine learning</a></li><li><a href="/wiki/Category:Artificial_intelligence" title="Category:Artificial intelligence">Artificial intelligence</a></li><li><a href="/wiki/Category:Computational_linguistics" title="Category:Computational linguistics">Computational linguistics</a></li><li><a href="/wiki/Category:Language_modeling" title="Category:Language modeling">Language modeling</a></li><li><a href="/wiki/Category:Natural_language_generation" title="Category:Natural language generation">Natural language generation</a></li><li><a href="/wiki/Category:Natural_language_processing" title="Category:Natural language processing">Natural language processing</a></li><li><a href="/wiki/Category:Neural_network_software" title="Category:Neural network software">Neural network software</a></li><li><a href="/wiki/Category:Open-source_artificial_intelligence" title="Category:Open-source artificial intelligence">Open-source artificial intelligence</a></li><li><a href="/wiki/Category:Software_using_the_MIT_license" title="Category:Software using the MIT license">Software using the MIT license</a></li><li><a href="/wiki/Category:Unsupervised_learning" title="Category:Unsupervised learning">Unsupervised learning</a></li></ul></div><div id="mw-hidden-catlinks" class="mw-hidden-catlinks mw-hidden-cats-hidden">Hidden categories: <ul><li><a href="/wiki/Category:CS1_errors:_missing_periodical" title="Category:CS1 errors: missing periodical">CS1 errors: missing periodical</a></li><li><a href="/wiki/Category:Articles_with_short_description" title="Category:Articles with short description">Articles with short description</a></li><li><a href="/wiki/Category:Short_description_is_different_from_Wikidata" title="Category:Short description is different from Wikidata">Short description is different from Wikidata</a></li></ul></div></div>
	</div>
</div>
<div id='mw-data-after-content'>
	<div class="read-more-container"></div>
</div>

<div id="mw-navigation">
	<h2>Navigation menu</h2>
	<div id="mw-head">
		
<nav id="p-personal" class="mw-portlet mw-portlet-personal vector-user-menu-legacy vector-menu" aria-labelledby="p-personal-label" role="navigation" 
	 >
	<h3 id="p-personal-label" aria-label="" class="vector-menu-heading">
		<span class="vector-menu-heading-label">Personal tools</span>
	</h3>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list"><li id="pt-anonuserpage" class="mw-list-item"><span>Not logged in</span></li><li id="pt-anontalk" class="mw-list-item"><a href="/wiki/Special:MyTalk" title="Discussion about edits from this IP address [n]" accesskey="n"><span>Talk</span></a></li><li id="pt-anoncontribs" class="mw-list-item"><a href="/wiki/Special:MyContributions" title="A list of edits made from this IP address [y]" accesskey="y"><span>Contributions</span></a></li><li id="pt-createaccount" class="mw-list-item"><a href="/w/index.php?title=Special:CreateAccount&amp;returnto=DALL-E" title="You are encouraged to create an account and log in; however, it is not mandatory"><span>Create account</span></a></li><li id="pt-login" class="mw-list-item"><a href="/w/index.php?title=Special:UserLogin&amp;returnto=DALL-E" title="You&#039;re encouraged to log in; however, it&#039;s not mandatory. [o]" accesskey="o"><span>Log in</span></a></li></ul>
		
	</div>
</nav>

		<div id="left-navigation">
			
<nav id="p-namespaces" class="mw-portlet mw-portlet-namespaces vector-menu vector-menu-tabs" aria-labelledby="p-namespaces-label" role="navigation" 
	 >
	<h3 id="p-namespaces-label" aria-label="" class="vector-menu-heading">
		<span class="vector-menu-heading-label">Namespaces</span>
	</h3>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list"><li id="ca-nstab-main" class="selected mw-list-item"><a href="/wiki/DALL-E" title="View the content page [c]" accesskey="c"><span>Article</span></a></li><li id="ca-talk" class="mw-list-item"><a href="/wiki/Talk:DALL-E" rel="discussion" title="Discuss improvements to the content page [t]" accesskey="t"><span>Talk</span></a></li></ul>
		
	</div>
</nav>

			
<nav id="p-variants" class="mw-portlet mw-portlet-variants emptyPortlet vector-menu-dropdown-noicon vector-menu vector-menu-dropdown" aria-labelledby="p-variants-label" role="navigation" 
	 >
	<input type="checkbox"
		id="p-variants-checkbox"
		role="button"
		aria-haspopup="true"
		data-event-name="ui.dropdown-p-variants"
		class="vector-menu-checkbox" aria-labelledby="p-variants-label" />
	<h3 id="p-variants-label" aria-label="Change language variant" class="vector-menu-heading">
		<span class="vector-menu-heading-label">English</span>
			<span class="vector-menu-checkbox-expanded">expanded</span>
			<span class="vector-menu-checkbox-collapsed">collapsed</span>
	</h3>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list"></ul>
		
	</div>
</nav>

		</div>
		<div id="right-navigation">
			
<nav id="p-views" class="mw-portlet mw-portlet-views vector-menu vector-menu-tabs" aria-labelledby="p-views-label" role="navigation" 
	 >
	<h3 id="p-views-label" aria-label="" class="vector-menu-heading">
		<span class="vector-menu-heading-label">Views</span>
	</h3>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list"><li id="ca-view" class="selected mw-list-item"><a href="/wiki/DALL-E"><span>Read</span></a></li><li id="ca-edit" class="mw-list-item"><a href="/w/index.php?title=DALL-E&amp;action=edit" title="Edit this page [e]" accesskey="e"><span>Edit</span></a></li><li id="ca-history" class="mw-list-item"><a href="/w/index.php?title=DALL-E&amp;action=history" title="Past revisions of this page [h]" accesskey="h"><span>View history</span></a></li></ul>
		
	</div>
</nav>

			
<nav id="p-cactions" class="mw-portlet mw-portlet-cactions emptyPortlet vector-menu-dropdown-noicon vector-menu vector-menu-dropdown" aria-labelledby="p-cactions-label" role="navigation"  title="More options"
	 >
	<input type="checkbox"
		id="p-cactions-checkbox"
		role="button"
		aria-haspopup="true"
		data-event-name="ui.dropdown-p-cactions"
		class="vector-menu-checkbox" aria-labelledby="p-cactions-label" />
	<h3 id="p-cactions-label" aria-label="" class="vector-menu-heading">
		<span class="vector-menu-heading-label">More</span>
			<span class="vector-menu-checkbox-expanded">expanded</span>
			<span class="vector-menu-checkbox-collapsed">collapsed</span>
	</h3>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list"></ul>
		
	</div>
</nav>

			
<div id="p-search" role="search" class="vector-search-box-vue  vector-search-box-show-thumbnail vector-search-box-auto-expand-width vector-search-box">
	<div>
			<h3 >
				<label for="searchInput">Search</label>
			</h3>
		<form action="/w/index.php" id="searchform"
			class="vector-search-box-form">
			<div id="simpleSearch"
				class="vector-search-box-inner"
				 data-search-loc="header-navigation">
				<input class="vector-search-box-input"
					 type="search" name="search" placeholder="Search Wikipedia" aria-label="Search Wikipedia" autocapitalize="sentences" title="Search Wikipedia [f]" accesskey="f" id="searchInput"
				/>
				<input type="hidden" name="title" value="Special:Search"/>
				<input id="mw-searchButton"
					 class="searchButton mw-fallbackSearchButton" type="submit" name="fulltext" title="Search Wikipedia for this text" value="Search" />
				<input id="searchButton"
					 class="searchButton" type="submit" name="go" title="Go to a page with this exact name if it exists" value="Go" />
			</div>
		</form>
	</div>
</div>

		</div>
	</div>
	

<div id="mw-panel">
	<div id="p-logo" role="banner">
		<a class="mw-wiki-logo" href="/wiki/Main_Page"
			title="Visit the main page"></a>
	</div>
	
<nav id="p-navigation" class="mw-portlet mw-portlet-navigation vector-menu vector-menu-portal portal" aria-labelledby="p-navigation-label" role="navigation" 
	 >
	<h3 id="p-navigation-label" aria-label="" class="vector-menu-heading">
		<span class="vector-menu-heading-label">Navigation</span>
	</h3>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list"><li id="n-mainpage-description" class="mw-list-item"><a href="/wiki/Main_Page" icon="home" title="Visit the main page [z]" accesskey="z"><span>Main page</span></a></li><li id="n-contents" class="mw-list-item"><a href="/wiki/Wikipedia:Contents" title="Guides to browsing Wikipedia"><span>Contents</span></a></li><li id="n-currentevents" class="mw-list-item"><a href="/wiki/Portal:Current_events" title="Articles related to current events"><span>Current events</span></a></li><li id="n-randompage" class="mw-list-item"><a href="/wiki/Special:Random" icon="die" title="Visit a randomly selected article [x]" accesskey="x"><span>Random article</span></a></li><li id="n-aboutsite" class="mw-list-item"><a href="/wiki/Wikipedia:About" title="Learn about Wikipedia and how it works"><span>About Wikipedia</span></a></li><li id="n-contactpage" class="mw-list-item"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia"><span>Contact us</span></a></li><li id="n-sitesupport" class="mw-list-item"><a href="https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikipedia.org&amp;uselang=en" title="Support us by donating to the Wikimedia Foundation"><span>Donate</span></a></li></ul>
		
	</div>
</nav>

	
<nav id="p-interaction" class="mw-portlet mw-portlet-interaction vector-menu vector-menu-portal portal" aria-labelledby="p-interaction-label" role="navigation" 
	 >
	<h3 id="p-interaction-label" aria-label="" class="vector-menu-heading">
		<span class="vector-menu-heading-label">Contribute</span>
	</h3>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list"><li id="n-help" class="mw-list-item"><a href="/wiki/Help:Contents" icon="help" title="Guidance on how to use and edit Wikipedia"><span>Help</span></a></li><li id="n-introduction" class="mw-list-item"><a href="/wiki/Help:Introduction" title="Learn how to edit Wikipedia"><span>Learn to edit</span></a></li><li id="n-portal" class="mw-list-item"><a href="/wiki/Wikipedia:Community_portal" title="The hub for editors"><span>Community portal</span></a></li><li id="n-recentchanges" class="mw-list-item"><a href="/wiki/Special:RecentChanges" icon="recentChanges" title="A list of recent changes to Wikipedia [r]" accesskey="r"><span>Recent changes</span></a></li><li id="n-upload" class="mw-list-item"><a href="/wiki/Wikipedia:File_Upload_Wizard" title="Add images or other media for use on Wikipedia"><span>Upload file</span></a></li></ul>
		
	</div>
</nav>

<nav id="p-tb" class="mw-portlet mw-portlet-tb vector-menu vector-menu-portal portal" aria-labelledby="p-tb-label" role="navigation" 
	 >
	<h3 id="p-tb-label" aria-label="" class="vector-menu-heading">
		<span class="vector-menu-heading-label">Tools</span>
	</h3>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list"><li id="t-whatlinkshere" class="mw-list-item"><a href="/wiki/Special:WhatLinksHere/DALL-E" title="List of all English Wikipedia pages containing links to this page [j]" accesskey="j"><span>What links here</span></a></li><li id="t-recentchangeslinked" class="mw-list-item"><a href="/wiki/Special:RecentChangesLinked/DALL-E" rel="nofollow" title="Recent changes in pages linked from this page [k]" accesskey="k"><span>Related changes</span></a></li><li id="t-upload" class="mw-list-item"><a href="/wiki/Wikipedia:File_Upload_Wizard" title="Upload files [u]" accesskey="u"><span>Upload file</span></a></li><li id="t-specialpages" class="mw-list-item"><a href="/wiki/Special:SpecialPages" title="A list of all special pages [q]" accesskey="q"><span>Special pages</span></a></li><li id="t-permalink" class="mw-list-item"><a href="/w/index.php?title=DALL-E&amp;oldid=1068645284" title="Permanent link to this revision of this page"><span>Permanent link</span></a></li><li id="t-info" class="mw-list-item"><a href="/w/index.php?title=DALL-E&amp;action=info" title="More information about this page"><span>Page information</span></a></li><li id="t-cite" class="mw-list-item"><a href="/w/index.php?title=Special:CiteThisPage&amp;page=DALL-E&amp;id=1068645284&amp;wpFormIdentifier=titleform" title="Information on how to cite this page"><span>Cite this page</span></a></li><li id="t-wikibase" class="mw-list-item"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q105078662" title="Structured data on this page hosted by Wikidata [g]" accesskey="g"><span>Wikidata item</span></a></li></ul>
		
	</div>
</nav>

<nav id="p-coll-print_export" class="mw-portlet mw-portlet-coll-print_export vector-menu vector-menu-portal portal" aria-labelledby="p-coll-print_export-label" role="navigation" 
	 >
	<h3 id="p-coll-print_export-label" aria-label="" class="vector-menu-heading">
		<span class="vector-menu-heading-label">Print/export</span>
	</h3>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list"><li id="coll-download-as-rl" class="mw-list-item"><a href="/w/index.php?title=Special:DownloadAsPdf&amp;page=DALL-E&amp;action=show-download-screen" title="Download this page as a PDF file"><span>Download as PDF</span></a></li><li id="t-print" class="mw-list-item"><a href="/w/index.php?title=DALL-E&amp;printable=yes" title="Printable version of this page [p]" accesskey="p"><span>Printable version</span></a></li></ul>
		
	</div>
</nav>

	
<nav id="p-lang" class="mw-portlet mw-portlet-lang vector-menu vector-menu-portal portal" aria-labelledby="p-lang-label" role="navigation" 
	 >
	<h3 id="p-lang-label" aria-label="" class="vector-menu-heading">
		<span class="vector-menu-heading-label">Languages</span>
	</h3>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list"><li class="interlanguage-link interwiki-ca mw-list-item"><a href="https://ca.wikipedia.org/wiki/Dall-e" title="Dall-e – Catalan" lang="ca" hreflang="ca" class="interlanguage-link-target"><span>Català</span></a></li><li class="interlanguage-link interwiki-es mw-list-item"><a href="https://es.wikipedia.org/wiki/Dall-e" title="Dall-e – Spanish" lang="es" hreflang="es" class="interlanguage-link-target"><span>Español</span></a></li><li class="interlanguage-link interwiki-ro mw-list-item"><a href="https://ro.wikipedia.org/wiki/DALL-E" title="DALL-E – Romanian" lang="ro" hreflang="ro" class="interlanguage-link-target"><span>Română</span></a></li><li class="interlanguage-link interwiki-tr mw-list-item"><a href="https://tr.wikipedia.org/wiki/DALL-E" title="DALL-E – Turkish" lang="tr" hreflang="tr" class="interlanguage-link-target"><span>Türkçe</span></a></li><li class="interlanguage-link interwiki-zh-yue mw-list-item"><a href="https://zh-yue.wikipedia.org/wiki/DALL-E" title="DALL-E – Cantonese" lang="yue" hreflang="yue" class="interlanguage-link-target"><span>粵語</span></a></li></ul>
		<div class="after-portlet after-portlet-lang"><span class="wb-langlinks-edit wb-langlinks-link"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q105078662#sitelinks-wikipedia" title="Edit interlanguage links" class="wbc-editpage">Edit links</a></span></div>
	</div>
</nav>

</div>

</div>

<footer id="footer" class="mw-footer" role="contentinfo" >
	<ul id="footer-info">
	<li id="footer-info-lastmod"> This page was last edited on 29 January 2022, at 15:54<span class="anonymous-show">&#160;(UTC)</span>.</li>
	<li id="footer-info-copyright">Text is available under the <a rel="license" href="//en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License">Creative Commons Attribution-ShareAlike License</a><a rel="license" href="//creativecommons.org/licenses/by-sa/3.0/" style="display:none;"></a>;
additional terms may apply.  By using this site, you agree to the <a href="//foundation.wikimedia.org/wiki/Terms_of_Use">Terms of Use</a> and <a href="//foundation.wikimedia.org/wiki/Privacy_policy">Privacy Policy</a>. Wikipedia® is a registered trademark of the <a href="//www.wikimediafoundation.org/">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li>
</ul>

	<ul id="footer-places">
	<li id="footer-places-privacy"><a href="https://foundation.wikimedia.org/wiki/Privacy_policy" class="extiw" title="wmf:Privacy policy">Privacy policy</a></li>
	<li id="footer-places-about"><a href="/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>
	<li id="footer-places-disclaimer"><a href="/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>
	<li id="footer-places-contact"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us">Contact Wikipedia</a></li>
	<li id="footer-places-mobileview"><a href="//en.m.wikipedia.org/w/index.php?title=DALL-E&amp;mobileaction=toggle_view_mobile" class="noprint stopMobileRedirectToggle">Mobile view</a></li>
	<li id="footer-places-developers"><a href="https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute">Developers</a></li>
	<li id="footer-places-statslink"><a href="https://stats.wikimedia.org/#/en.wikipedia.org">Statistics</a></li>
	<li id="footer-places-cookiestatement"><a href="https://foundation.wikimedia.org/wiki/Cookie_statement">Cookie statement</a></li>
</ul>

	<ul id="footer-icons" class="noprint">
	<li id="footer-copyrightico"><a href="https://wikimediafoundation.org/"><img src="/static/images/footer/wikimedia-button.png" srcset="/static/images/footer/wikimedia-button-1.5x.png 1.5x, /static/images/footer/wikimedia-button-2x.png 2x" width="88" height="31" alt="Wikimedia Foundation" loading="lazy" /></a></li>
	<li id="footer-poweredbyico"><a href="https://www.mediawiki.org/"><img src="/static/images/footer/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" srcset="/static/images/footer/poweredby_mediawiki_132x47.png 1.5x, /static/images/footer/poweredby_mediawiki_176x62.png 2x" width="88" height="31" loading="lazy"/></a></li>
</ul>

</footer>

<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgPageParseReport":{"limitreport":{"cputime":"0.615","walltime":"0.728","ppvisitednodes":{"value":2746,"limit":1000000},"postexpandincludesize":{"value":104353,"limit":2097152},"templateargumentsize":{"value":1554,"limit":2097152},"expansiondepth":{"value":13,"limit":100},"expensivefunctioncount":{"value":3,"limit":500},"unstrip-depth":{"value":1,"limit":20},"unstrip-size":{"value":105789,"limit":5000000},"entityaccesscount":{"value":1,"limit":400},"timingprofile":["100.00%  630.556      1 -total"," 30.85%  194.540     22 Template:Cite_web"," 12.47%   78.604      1 Template:Artificial_intelligence"," 12.04%   75.914      1 Template:Sidebar_with_collapsible_lists"," 11.00%   69.388      1 Template:Infobox_software"," 10.12%   63.803      1 Template:Infobox","  9.47%   59.726      1 Template:Short_description","  9.37%   59.087      1 Template:Differentiable_computing","  9.34%   58.924      2 Template:Navbox","  5.66%   35.682      3 Template:Cite_arXiv"]},"scribunto":{"limitreport-timeusage":{"value":"0.375","limit":"10.000"},"limitreport-memusage":{"value":7098581,"limit":52428800}},"cachereport":{"origin":"mw1403","timestamp":"20220212190319","ttl":1814400,"transientcontent":false}}});});</script>
<script type="application/ld+json">{"@context":"https:\/\/schema.org","@type":"Article","name":"DALL-E","url":"https:\/\/en.wikipedia.org\/wiki\/DALL-E","sameAs":"http:\/\/www.wikidata.org\/entity\/Q105078662","mainEntity":"http:\/\/www.wikidata.org\/entity\/Q105078662","author":{"@type":"Organization","name":"Contributors to Wikimedia projects"},"publisher":{"@type":"Organization","name":"Wikimedia Foundation, Inc.","logo":{"@type":"ImageObject","url":"https:\/\/www.wikimedia.org\/static\/images\/wmf-hor-googpub.png"}},"datePublished":"2021-01-06T07:14:38Z","dateModified":"2022-01-29T15:54:15Z","image":"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/a\/a3\/DALL-E_sample.png","headline":"artificial intelligence program"}</script>
<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgBackendResponseTime":179,"wgHostname":"mw1391"});});</script>
</body>
</html>