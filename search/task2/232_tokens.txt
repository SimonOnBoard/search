deep
learning
wikipedia
free
encyclopedia
jump
navigation
jump
search
branch
machine
learning
mw
parser
output
hatnote
font
style
italic
mw
parser
output
div
hatnote
padding
left
em
margin
bottom
em
mw
parser
output
hatnote
font
style
normal
mw
parser
output
hatnote
link
hatnote
margin
top
em
deep
versus
shallow
learning
educational
psychology
see
student
approaches
learning
information
see
artificial
neural
network
representing
images
multiple
layers
abstraction
deep
learning
mw
parser
output
sidebar
width
em
float
right
clear
right
margin
em
em
em
background
f
f
fa
border
px
solid
aaa
padding
em
text
align
center
line
height
em
font
size
border
collapse
collapse
display
table
body
skin
minerva
mw
parser
output
sidebar
display
table
important
float
right
important
margin
em
em
em
important
mw
parser
output
sidebar
subgroup
width
margin
border
spacing
mw
parser
output
sidebar
left
float
left
clear
left
margin
em
em
em
mw
parser
output
sidebar
none
float
none
clear
margin
em
em
em
mw
parser
output
sidebar
outer
title
padding
em
em
font
size
line
height
em
font
weight
bold
mw
parser
output
sidebar
top
image
padding
em
mw
parser
output
sidebar
top
caption
mw
parser
output
sidebar
pretitle
top
image
mw
parser
output
sidebar
caption
padding
em
em
line
height
em
mw
parser
output
sidebar
pretitle
padding
em
em
line
height
em
mw
parser
output
sidebar
title
mw
parser
output
sidebar
title
pretitle
padding
em
em
font
size
line
height
em
mw
parser
output
sidebar
title
pretitle
padding
em
em
mw
parser
output
sidebar
image
padding
em
em
em
mw
parser
output
sidebar
heading
padding
em
em
mw
parser
output
sidebar
content
padding
em
em
mw
parser
output
sidebar
content
subgroup
padding
em
em
em
mw
parser
output
sidebar
mw
parser
output
sidebar
padding
em
em
font
weight
bold
mw
parser
output
sidebar
collapse
sidebar
mw
parser
output
sidebar
collapse
sidebar
border
top
px
solid
aaa
border
bottom
px
solid
aaa
mw
parser
output
sidebar
navbar
text
align
right
font
size
padding
em
em
mw
parser
output
sidebar
list
title
padding
em
text
align
left
font
weight
bold
line
height
em
font
size
mw
parser
output
sidebar
list
title
c
padding
em
text
align
center
margin
em
max
width
px
body
mediawiki
mw
parser
output
sidebar
width
important
clear
float
none
important
margin
left
important
margin
right
important
part
series
machine
learning
data
mining
problems
classification
clustering
regression
anomaly
detection
data
cleaning
automl
association
rules
reinforcement
learning
structured
prediction
feature
engineering
feature
learning
online
learning
semi
supervised
learning
unsupervised
learning
learning
rank
grammar
induction
supervised
learning
mw
parser
output
nobold
font
weight
normal
classification
regression
decision
trees
ensembles
bagging
boosting
random
forest
k
nn
linear
regression
naive
bayes
artificial
neural
networks
logistic
regression
perceptron
relevance
vector
machine
rvm
support
vector
machine
svm
clustering
birch
cure
hierarchical
k
means
expectation
maximization
em
dbscan
optics
mean
shift
dimensionality
reduction
factor
analysis
cca
ica
lda
nmf
pca
pgd
sne
structured
prediction
graphical
models
bayes
net
conditional
random
field
hidden
markov
anomaly
detection
k
nn
local
outlier
factor
artificial
neural
network
autoencoder
cognitive
computing
deep
learning
deepdream
multilayer
perceptron
rnn
lstm
gru
esn
restricted
boltzmann
machine
gan
som
convolutional
neural
network
u
net
transformer
vision
spiking
neural
network
memtransistor
electrochemical
ram
ecram
reinforcement
learning
q
learning
sarsa
temporal
difference
td
theory
kernel
machines
bias
variance
tradeoff
computational
learning
theory
empirical
risk
minimization
occam
learning
pac
learning
statistical
learning
vc
theory
machine
learning
venues
neurips
icml
ml
jmlr
arxiv
cs
lg
related
articles
glossary
artificial
intelligence
list
datasets
machine
learning
research
outline
machine
learning
mw
parser
output
navbar
display
inline
font
size
font
weight
normal
mw
parser
output
navbar
collapse
float
left
text
align
left
mw
parser
output
navbar
boxtext
word
spacing
mw
parser
output
navbar
ul
display
inline
block
white
space
nowrap
line
height
inherit
mw
parser
output
navbar
brackets
margin
right
em
content
mw
parser
output
navbar
brackets
margin
left
em
content
mw
parser
output
navbar
li
word
spacing
em
mw
parser
output
navbar
span
mw
parser
output
navbar
abbr
text
decoration
inherit
mw
parser
output
navbar
mini
abbr
font
variant
small
caps
border
bottom
none
text
decoration
none
cursor
inherit
mw
parser
output
navbar
ct
full
font
size
margin
em
mw
parser
output
navbar
ct
mini
font
size
margin
em
v
e
part
series
artificial
intelligence
major
goals
artificial
general
intelligence
planning
computer
vision
general
game
playing
knowledge
reasoning
machine
learning
natural
language
processing
robotics
approaches
symbolic
deep
learning
bayesian
networks
evolutionary
algorithms
philosophy
chinese
room
friendly
ai
control
problem
takeover
ethics
existential
risk
turing
test
history
timeline
progress
ai
winter
technology
applications
projects
programming
languages
glossary
glossary
v
e
deep
learning
also
known
deep
structured
learning
part
broader
family
machine
learning
methods
based
artificial
neural
networks
representation
learning
learning
supervised
semi
supervised
unsupervised
deep
learning
architectures
deep
neural
networks
deep
belief
networks
deep
reinforcement
learning
recurrent
neural
networks
convolutional
neural
networks
applied
fields
including
computer
vision
speech
recognition
natural
language
processing
machine
translation
bioinformatics
drug
design
medical
image
analysis
climate
science
material
inspection
board
game
programs
produced
results
comparable
cases
surpassing
human
expert
performance
artificial
neural
networks
anns
inspired
information
processing
distributed
communication
nodes
biological
systems
anns
various
differences
biological
brains
specifically
artificial
neural
networks
tend
static
symbolic
biological
brain
living
organisms
dynamic
plastic
analogue
adjective
deep
deep
learning
refers
use
multiple
layers
network
early
work
showed
linear
perceptron
cannot
universal
classifier
network
nonpolynomial
activation
function
one
hidden
layer
unbounded
width
deep
learning
modern
variation
concerned
unbounded
number
layers
bounded
size
permits
practical
application
optimized
implementation
retaining
theoretical
universality
mild
conditions
deep
learning
layers
also
permitted
heterogeneous
deviate
widely
biologically
informed
connectionist
models
sake
efficiency
trainability
understandability
whence
structured
part
mw
parser
output
toclimit
toclevel
ul
mw
parser
output
toclimit
toclevel
ul
mw
parser
output
toclimit
toclevel
ul
mw
parser
output
toclimit
toclevel
ul
mw
parser
output
toclimit
toclevel
ul
mw
parser
output
toclimit
toclevel
ul
display
none
contents
definition
overview
interpretations
history
deep
learning
revolution
neural
networks
artificial
neural
networks
deep
neural
networks
challenges
hardware
applications
automatic
speech
recognition
image
recognition
visual
art
processing
natural
language
processing
drug
discovery
toxicology
climate
science
customer
relationship
management
recommendation
systems
bioinformatics
medical
image
analysis
mobile
advertising
image
restoration
financial
fraud
detection
military
partial
differential
equations
relation
human
cognitive
brain
development
commercial
activity
criticism
comment
theory
errors
cyber
threat
reliance
human
microwork
see
also
references
reading
definition
edit
deep
learning
class
machine
learning
algorithms
uses
multiple
layers
progressively
extract
higher
level
features
raw
input
example
image
processing
lower
layers
may
identify
edges
higher
layers
may
identify
concepts
relevant
human
digits
letters
faces
overview
edit
modern
deep
learning
models
based
artificial
neural
networks
specifically
convolutional
neural
networks
cnn
although
also
include
propositional
formulas
latent
variables
organized
layer
wise
deep
generative
models
nodes
deep
belief
networks
deep
boltzmann
machines
deep
learning
level
learns
transform
input
data
slightly
abstract
composite
representation
image
recognition
application
raw
input
may
matrix
pixels
first
representational
layer
may
abstract
pixels
encode
edges
second
layer
may
compose
encode
arrangements
edges
third
layer
may
encode
nose
eyes
fourth
layer
may
recognize
image
contains
face
importantly
deep
learning
process
learn
features
optimally
place
level
completely
eliminate
need
hand
tuning
example
varying
numbers
layers
layer
sizes
provide
different
degrees
abstraction
word
deep
deep
learning
refers
number
layers
data
transformed
precisely
deep
learning
systems
substantial
credit
assignment
path
cap
depth
cap
chain
transformations
input
output
caps
describe
potentially
causal
connections
input
output
feedforward
neural
network
depth
caps
network
number
hidden
layers
plus
one
output
layer
also
parameterized
recurrent
neural
networks
signal
may
propagate
layer
cap
depth
potentially
unlimited
universally
agreed
upon
threshold
depth
divides
shallow
learning
deep
learning
researchers
agree
deep
learning
involves
cap
depth
higher
cap
depth
shown
universal
approximator
sense
emulate
function
beyond
layers
add
function
approximator
ability
network
deep
models
cap
able
extract
better
features
shallow
models
hence
extra
layers
help
learning
features
effectively
deep
learning
architectures
constructed
greedy
layer
layer
method
deep
learning
helps
disentangle
abstractions
pick
features
improve
performance
supervised
learning
tasks
deep
learning
methods
eliminate
feature
engineering
translating
data
compact
intermediate
representations
akin
principal
components
derive
layered
structures
remove
redundancy
representation
deep
learning
algorithms
applied
unsupervised
learning
tasks
important
benefit
unlabeled
data
abundant
labeled
data
examples
deep
structures
trained
unsupervised
manner
neural
history
compressors
deep
belief
networks
interpretations
edit
deep
neural
networks
generally
interpreted
terms
universal
approximation
theorem
probabilistic
inference
classic
universal
approximation
theorem
concerns
capacity
feedforward
neural
networks
single
hidden
layer
finite
size
approximate
continuous
functions
first
proof
published
george
cybenko
sigmoid
activation
functions
generalised
feed
forward
multi
layer
architectures
kurt
hornik
recent
work
also
showed
universal
approximation
also
holds
non
bounded
activation
functions
rectified
linear
unit
universal
approximation
theorem
deep
neural
networks
concerns
capacity
networks
bounded
width
depth
allowed
grow
lu
et
al
proved
width
deep
neural
network
relu
activation
strictly
larger
input
dimension
network
approximate
lebesgue
integrable
function
width
smaller
equal
input
dimension
deep
neural
network
universal
approximator
probabilistic
interpretation
derives
field
machine
learning
features
inference
well
optimization
concepts
training
testing
related
fitting
generalization
respectively
specifically
probabilistic
interpretation
considers
activation
nonlinearity
cumulative
distribution
function
probabilistic
interpretation
led
introduction
dropout
regularizer
neural
networks
probabilistic
interpretation
introduced
researchers
including
hopfield
widrow
narendra
popularized
surveys
one
bishop
history
edit
sources
point
frank
rosenblatt
developed
explored
basic
ingredients
deep
learning
systems
today
described
book
principles
neurodynamics
perceptrons
theory
brain
mechanisms
published
cornell
aeronautical
laboratory
inc
cornell
university
first
general
working
learning
algorithm
supervised
deep
feedforward
multilayer
perceptrons
published
alexey
ivakhnenko
lapa
paper
described
deep
network
eight
layers
trained
group
method
data
handling
deep
learning
working
architectures
specifically
built
computer
vision
began
neocognitron
introduced
kunihiko
fukushima
term
deep
learning
introduced
machine
learning
community
rina
dechter
artificial
neural
networks
igor
aizenberg
colleagues
context
boolean
threshold
neurons
yann
lecun
et
al
applied
standard
backpropagation
algorithm
around
reverse
mode
automatic
differentiation
since
deep
neural
network
purpose
recognizing
handwritten
zip
codes
mail
algorithm
worked
training
required
days
andr
de
carvalho
together
mike
fairhurst
david
bisset
published
experimental
results
multi
layer
boolean
neural
network
also
known
weightless
neural
network
composed
layers
self
organising
feature
extraction
neural
network
module
soft
followed
multi
layer
classification
neural
network
module
gsn
independently
trained
layer
feature
extraction
module
extracted
features
growing
complexity
regarding
previous
layer
brendan
frey
demonstrated
possible
train
two
days
network
containing
six
fully
connected
layers
several
hundred
hidden
units
using
wake
sleep
algorithm
co
developed
peter
dayan
hinton
many
factors
contribute
slow
speed
including
vanishing
gradient
problem
analyzed
sepp
hochreiter
since
sven
behnke
extended
feed
forward
hierarchical
convolutional
approach
neural
abstraction
pyramid
lateral
backward
connections
order
flexibly
incorporate
context
decisions
iteratively
resolve
local
ambiguities
simpler
models
use
task
specific
handcrafted
features
gabor
filters
support
vector
machines
svms
popular
choice
artificial
neural
network
ann
computational
cost
lack
understanding
brain
wires
biological
networks
shallow
deep
learning
e
g
recurrent
nets
anns
explored
many
years
methods
never
outperformed
non
uniform
internal
handcrafting
gaussian
mixture
model
hidden
markov
model
gmm
hmm
technology
based
generative
models
speech
trained
discriminatively
key
difficulties
analyzed
including
gradient
diminishing
weak
temporal
correlation
structure
neural
predictive
models
additional
difficulties
lack
training
data
limited
computing
power
speech
recognition
researchers
moved
away
neural
nets
pursue
generative
modeling
exception
sri
international
late
funded
us
government
nsa
darpa
sri
studied
deep
neural
networks
speech
speaker
recognition
speaker
recognition
team
led
larry
heck
reported
significant
success
deep
neural
networks
speech
processing
national
institute
standards
technology
speaker
recognition
evaluation
sri
deep
neural
network
deployed
nuance
verifier
representing
first
major
industrial
application
deep
learning
principle
elevating
raw
features
hand
crafted
optimization
first
explored
successfully
architecture
deep
autoencoder
raw
spectrogram
linear
filter
bank
features
late
showing
superiority
mel
cepstral
features
contain
stages
fixed
transformation
spectrograms
raw
features
speech
waveforms
later
produced
excellent
larger
scale
results
many
aspects
speech
recognition
taken
deep
learning
method
called
long
short
term
memory
lstm
recurrent
neural
network
published
hochreiter
schmidhuber
lstm
rnns
avoid
vanishing
gradient
problem
learn
deep
learning
tasks
require
memories
events
happened
thousands
discrete
time
steps
important
speech
lstm
started
become
competitive
traditional
speech
recognizers
certain
tasks
later
combined
connectionist
temporal
classification
ctc
stacks
lstm
rnns
google
speech
recognition
reportedly
experienced
dramatic
performance
jump
ctc
trained
lstm
made
available
google
voice
search
publications
geoff
hinton
ruslan
salakhutdinov
osindero
teh
showed
many
layered
feedforward
neural
network
could
effectively
pre
trained
one
layer
time
treating
layer
turn
unsupervised
restricted
boltzmann
machine
fine
tuning
using
supervised
backpropagation
papers
referred
learning
deep
belief
nets
deep
learning
part
state
art
systems
various
disciplines
particularly
computer
vision
automatic
speech
recognition
asr
results
commonly
used
evaluation
sets
timit
asr
mnist
image
classification
well
range
large
vocabulary
speech
recognition
tasks
steadily
improved
convolutional
neural
networks
cnns
superseded
asr
ctc
lstm
successful
computer
vision
impact
deep
learning
industry
began
early
cnns
already
processed
estimated
checks
written
us
according
yann
lecun
industrial
applications
deep
learning
large
scale
speech
recognition
started
around
nips
workshop
deep
learning
speech
recognition
motivated
limitations
deep
generative
models
speech
possibility
given
capable
hardware
large
scale
data
sets
deep
neural
nets
dnn
might
become
practical
believed
pre
training
dnns
using
generative
models
deep
belief
nets
dbn
would
overcome
main
difficulties
neural
nets
however
discovered
replacing
pre
training
large
amounts
training
data
straightforward
backpropagation
using
dnns
large
context
dependent
output
layers
produced
error
rates
dramatically
lower
state
art
gaussian
mixture
model
gmm
hidden
markov
model
hmm
also
advanced
generative
model
based
systems
nature
recognition
errors
produced
two
types
systems
characteristically
different
offering
technical
insights
integrate
deep
learning
existing
highly
efficient
run
time
speech
decoding
system
deployed
major
speech
recognition
systems
analysis
around
contrasting
gmm
generative
speech
models
vs
dnn
models
stimulated
early
industrial
investment
deep
learning
speech
recognition
eventually
leading
pervasive
dominant
use
industry
analysis
done
comparable
performance
less
error
rate
discriminative
dnns
generative
models
researchers
extended
deep
learning
timit
large
vocabulary
speech
recognition
adopting
large
output
layers
dnn
based
context
dependent
hmm
states
constructed
decision
trees
advances
hardware
driven
renewed
interest
deep
learning
nvidia
involved
called
big
bang
deep
learning
deep
learning
neural
networks
trained
nvidia
graphics
processing
units
gpus
year
andrew
ng
determined
gpus
could
increase
speed
deep
learning
systems
times
particular
gpus
well
suited
matrix
vector
computations
involved
machine
learning
gpus
speed
training
algorithms
orders
magnitude
reducing
running
times
weeks
days
specialized
hardware
algorithm
optimizations
used
efficient
processing
deep
learning
models
deep
learning
revolution
edit
deep
learning
subset
machine
learning
machine
learning
subset
artificial
intelligence
ai
team
led
george
e
dahl
merck
molecular
activity
challenge
using
multi
task
deep
neural
networks
predict
biomolecular
target
one
drug
hochreiter
group
used
deep
learning
detect
target
toxic
effects
environmental
chemicals
nutrients
household
products
drugs
tox
data
challenge
nih
fda
ncats
significant
additional
impacts
image
object
recognition
felt
although
cnns
trained
backpropagation
around
decades
gpu
implementations
nns
years
including
cnns
fast
implementations
cnns
gpus
needed
progress
computer
vision
approach
achieved
first
time
superhuman
performance
visual
pattern
recognition
contest
also
icdar
chinese
handwriting
contest
may
isbi
image
segmentation
contest
cnns
play
major
role
computer
vision
conferences
june
paper
ciresan
et
al
leading
conference
cvpr
showed
max
pooling
cnns
gpu
dramatically
improve
many
vision
benchmark
records
october
similar
system
krizhevsky
et
al
large
scale
imagenet
competition
significant
margin
shallow
machine
learning
methods
november
ciresan
et
al
system
also
icpr
contest
analysis
large
medical
images
cancer
detection
following
year
also
miccai
grand
challenge
topic
error
rate
imagenet
task
using
deep
learning
reduced
following
similar
trend
large
scale
speech
recognition
image
classification
extended
challenging
task
generating
descriptions
captions
images
often
combination
cnns
lstms
researchers
state
october
imagenet
victory
anchored
start
deep
learning
revolution
transformed
ai
industry
march
yoshua
bengio
geoffrey
hinton
yann
lecun
awarded
turing
award
conceptual
engineering
breakthroughs
made
deep
neural
networks
critical
component
computing
primary
component
analysis
selects
best
features
contribute
diabetic
retinopathy
classification
deep
neural
network
performs
better
random
forest
support
vector
machine
algorithms
neural
networks
edit
artificial
neural
networks
edit
main
article
artificial
neural
network
artificial
neural
networks
anns
connectionist
systems
computing
systems
inspired
biological
neural
networks
constitute
animal
brains
systems
learn
progressively
improve
ability
tasks
considering
examples
generally
without
task
specific
programming
example
image
recognition
might
learn
identify
images
contain
cats
analyzing
example
images
manually
labeled
cat
cat
using
analytic
results
identify
cats
images
found
use
applications
difficult
express
traditional
computer
algorithm
using
rule
based
programming
ann
based
collection
connected
units
called
artificial
neurons
analogous
biological
neurons
biological
brain
connection
synapse
neurons
transmit
signal
another
neuron
receiving
postsynaptic
neuron
process
signal
signal
downstream
neurons
connected
neurons
may
state
generally
represented
real
numbers
typically
neurons
synapses
may
also
weight
varies
learning
proceeds
increase
decrease
strength
signal
sends
downstream
typically
neurons
organized
layers
different
layers
may
perform
different
kinds
transformations
inputs
signals
travel
first
input
last
output
layer
possibly
traversing
layers
multiple
times
original
goal
neural
network
approach
solve
problems
way
human
brain
would
time
attention
focused
matching
specific
mental
abilities
leading
deviations
biology
backpropagation
passing
information
reverse
direction
adjusting
network
reflect
information
neural
networks
used
variety
tasks
including
computer
vision
speech
recognition
machine
translation
social
network
filtering
playing
board
video
games
medical
diagnosis
neural
networks
typically
thousand
million
units
millions
connections
despite
number
several
order
magnitude
less
number
neurons
human
brain
networks
perform
many
tasks
level
beyond
humans
e
g
recognizing
faces
playing
go
deep
neural
networks
edit
section
may
technical
readers
understand
please
help
improve
make
understandable
non
experts
without
removing
technical
details
july
learn
remove
template
message
deep
neural
network
dnn
artificial
neural
network
ann
multiple
layers
input
output
layers
different
types
neural
networks
always
consist
components
neurons
synapses
weights
biases
functions
components
functioning
similar
human
brains
trained
like
ml
algorithm
citation
needed
example
dnn
trained
recognize
dog
breeds
go
given
image
calculate
probability
dog
image
certain
breed
user
review
results
select
probabilities
network
display
certain
threshold
etc
return
proposed
label
mathematical
manipulation
considered
layer
complex
dnn
many
layers
hence
name
deep
networks
dnns
model
complex
non
linear
relationships
dnn
architectures
generate
compositional
models
object
expressed
layered
composition
primitives
extra
layers
enable
composition
features
lower
layers
potentially
modeling
complex
data
fewer
units
similarly
performing
shallow
network
instance
proved
sparse
multivariate
polynomials
exponentially
easier
approximate
dnns
shallow
networks
deep
architectures
include
many
variants
basic
approaches
architecture
found
success
specific
domains
always
possible
compare
performance
multiple
architectures
unless
evaluated
data
sets
dnns
typically
feedforward
networks
data
flows
input
layer
output
layer
without
looping
back
first
dnn
creates
map
virtual
neurons
assigns
random
numerical
values
weights
connections
weights
inputs
multiplied
return
output
network
accurately
recognize
particular
pattern
algorithm
would
adjust
weights
way
algorithm
make
certain
parameters
influential
determines
correct
mathematical
manipulation
fully
process
data
recurrent
neural
networks
rnns
data
flow
direction
used
applications
language
modeling
long
short
term
memory
particularly
effective
use
convolutional
deep
neural
networks
cnns
used
computer
vision
cnns
also
applied
acoustic
modeling
automatic
speech
recognition
asr
challenges
edit
anns
many
issues
arise
naively
trained
dnns
two
common
issues
overfitting
computation
time
dnns
prone
overfitting
added
layers
abstraction
allow
model
rare
dependencies
training
data
regularization
methods
ivakhnenko
unit
pruning
weight
decay
displaystyle
ell
regularization
sparsity
displaystyle
ell
regularization
applied
training
combat
overfitting
alternatively
dropout
regularization
randomly
omits
units
hidden
layers
training
helps
exclude
rare
dependencies
finally
data
augmented
via
methods
cropping
rotating
smaller
training
sets
increased
size
reduce
chances
overfitting
dnns
must
consider
many
training
parameters
size
number
layers
number
units
per
layer
learning
rate
initial
weights
sweeping
parameter
space
optimal
parameters
may
feasible
due
cost
time
computational
resources
various
tricks
batching
computing
gradient
several
training
examples
rather
individual
examples
speed
computation
large
processing
capabilities
many
core
architectures
gpus
intel
xeon
phi
produced
significant
speedups
training
suitability
processing
architectures
matrix
vector
computations
alternatively
engineers
may
look
types
neural
networks
straightforward
convergent
training
algorithms
cmac
cerebellar
model
articulation
controller
one
kind
neural
network
require
learning
rates
randomized
initial
weights
cmac
training
process
guaranteed
converge
one
step
new
batch
data
computational
complexity
training
algorithm
linear
respect
number
neurons
involved
hardware
edit
since
advances
machine
learning
algorithms
computer
hardware
led
efficient
methods
training
deep
neural
networks
contain
many
layers
non
linear
hidden
units
large
output
layer
graphic
processing
units
gpus
often
ai
specific
enhancements
displaced
cpus
dominant
method
training
large
scale
commercial
cloud
ai
openai
estimated
hardware
computation
used
largest
deep
learning
projects
alexnet
alphazero
found
fold
increase
amount
computation
required
doubling
time
trendline
months
applications
edit
automatic
speech
recognition
edit
main
article
speech
recognition
large
scale
automatic
speech
recognition
first
convincing
successful
case
deep
learning
lstm
rnns
learn
deep
learning
tasks
involve
multi
second
intervals
containing
speech
events
separated
thousands
discrete
time
steps
one
time
step
corresponds
ms
lstm
forget
gates
competitive
traditional
speech
recognizers
certain
tasks
initial
success
speech
recognition
based
small
scale
recognition
tasks
based
timit
data
set
contains
speakers
eight
major
dialects
american
english
speaker
reads
sentences
small
size
lets
many
configurations
tried
importantly
timit
task
concerns
phone
sequence
recognition
unlike
word
sequence
recognition
allows
weak
phone
bigram
language
models
lets
strength
acoustic
modeling
aspects
speech
recognition
easily
analyzed
error
rates
listed
including
early
results
measured
percent
phone
error
rates
per
summarized
since
method
percent
phone
error
rate
per
randomly
initialized
rnn
bayesian
triphone
gmm
hmm
hidden
trajectory
generative
model
monophone
randomly
initialized
dnn
monophone
dbn
dnn
triphone
gmm
hmm
bmmi
training
monophone
dbn
dnn
fbank
convolutional
dnn
convolutional
dnn
w
heterogeneous
pooling
ensemble
dnn
cnn
rnn
bidirectional
lstm
hierarchical
convolutional
deep
maxout
network
debut
dnns
speaker
recognition
late
speech
recognition
around
lstm
around
accelerated
progress
eight
major
areas
scale
accelerated
dnn
training
decoding
sequence
discriminative
training
feature
processing
deep
models
solid
understanding
underlying
mechanisms
adaptation
dnns
related
deep
models
multi
task
transfer
learning
dnns
related
deep
models
cnns
design
best
exploit
domain
knowledge
speech
rnn
rich
lstm
variants
types
deep
models
including
tensor
based
models
integrated
deep
generative
discriminative
models
major
commercial
speech
recognition
systems
e
g
microsoft
cortana
xbox
skype
translator
amazon
alexa
google
apple
siri
baidu
iflytek
voice
search
range
nuance
speech
products
etc
based
deep
learning
image
recognition
edit
main
article
computer
vision
common
evaluation
set
image
classification
mnist
database
data
set
mnist
composed
handwritten
digits
includes
training
examples
test
examples
timit
small
size
lets
users
test
multiple
configurations
comprehensive
list
results
set
available
deep
learning
based
image
recognition
become
superhuman
producing
accurate
results
human
contestants
first
occurred
recognition
traffic
signs
recognition
human
faces
surpassing
human
level
face
recognition
deep
learning
trained
vehicles
interpret
camera
views
another
example
facial
dysmorphology
novel
analysis
fdna
used
analyze
cases
human
malformation
connected
large
database
genetic
syndromes
visual
art
processing
edit
closely
related
progress
made
image
recognition
increasing
application
deep
learning
techniques
various
visual
art
tasks
dnns
proven
capable
example
identifying
style
period
given
painting
b
neural
style
transfer
capturing
style
given
artwork
applying
visually
pleasing
manner
arbitrary
photograph
video
c
generating
striking
imagery
based
random
visual
input
fields
natural
language
processing
edit
main
article
natural
language
processing
neural
networks
used
implementing
language
models
since
early
lstm
helped
improve
machine
translation
language
modeling
key
techniques
field
negative
sampling
word
embedding
word
embedding
word
vec
thought
representational
layer
deep
learning
architecture
transforms
atomic
word
positional
representation
word
relative
words
dataset
position
represented
point
vector
space
using
word
embedding
rnn
input
layer
allows
network
parse
sentences
phrases
using
effective
compositional
vector
grammar
compositional
vector
grammar
thought
probabilistic
context
free
grammar
pcfg
implemented
rnn
recursive
auto
encoders
built
atop
word
embeddings
assess
sentence
similarity
detect
paraphrasing
deep
neural
architectures
provide
best
results
constituency
parsing
sentiment
analysis
information
retrieval
spoken
language
understanding
machine
translation
contextual
entity
linking
writing
style
recognition
text
classification
others
recent
developments
generalize
word
embedding
sentence
embedding
google
translate
gt
uses
large
end
end
long
short
term
memory
lstm
network
google
neural
machine
translation
gnmt
uses
example
based
machine
translation
method
system
learns
millions
examples
translates
whole
sentences
time
rather
pieces
google
translate
supports
one
hundred
languages
network
encodes
semantics
sentence
rather
simply
memorizing
phrase
phrase
translations
gt
uses
english
intermediate
language
pairs
drug
discovery
toxicology
edit
information
see
drug
discovery
toxicology
large
percentage
candidate
drugs
fail
win
regulatory
approval
failures
caused
insufficient
efficacy
target
effect
undesired
interactions
target
effects
unanticipated
toxic
effects
research
explored
use
deep
learning
predict
biomolecular
targets
targets
toxic
effects
environmental
chemicals
nutrients
household
products
drugs
atomnet
deep
learning
system
structure
based
rational
drug
design
atomnet
used
predict
novel
candidate
biomolecules
disease
targets
ebola
virus
multiple
sclerosis
graph
neural
networks
used
first
time
predict
various
properties
molecules
large
toxicology
data
set
generative
neural
networks
used
produce
molecules
validated
experimentally
way
mice
climate
science
edit
deep
learning
successfully
applied
variety
prediction
tasks
across
earth
climate
sciences
including
applications
emulation
super
resolution
post
hoc
explainability
customer
relationship
management
edit
main
article
customer
relationship
management
deep
reinforcement
learning
used
approximate
value
possible
direct
marketing
actions
defined
terms
rfm
variables
estimated
value
function
shown
natural
interpretation
customer
lifetime
value
recommendation
systems
edit
main
article
recommender
system
recommendation
systems
used
deep
learning
extract
meaningful
features
latent
factor
model
content
based
music
journal
recommendations
multi
view
deep
learning
applied
learning
user
preferences
multiple
domains
model
uses
hybrid
collaborative
content
based
approach
enhances
recommendations
multiple
tasks
bioinformatics
edit
main
article
bioinformatics
autoencoder
ann
used
bioinformatics
predict
gene
ontology
annotations
gene
function
relationships
medical
informatics
deep
learning
used
predict
sleep
quality
based
data
wearables
predictions
health
complications
electronic
health
record
data
medical
image
analysis
edit
deep
learning
shown
produce
competitive
results
medical
application
cancer
cell
classification
lesion
detection
organ
segmentation
image
enhancement
mobile
advertising
edit
finding
appropriate
mobile
audience
mobile
advertising
always
challenging
since
many
data
points
must
considered
analyzed
target
segment
created
used
ad
serving
ad
server
deep
learning
used
interpret
large
many
dimensioned
advertising
datasets
many
data
points
collected
request
serve
click
internet
advertising
cycle
information
form
basis
machine
learning
improve
ad
selection
image
restoration
edit
deep
learning
successfully
applied
inverse
problems
denoising
super
resolution
inpainting
film
colorization
applications
include
learning
methods
shrinkage
fields
effective
image
restoration
trains
image
dataset
deep
image
prior
trains
image
needs
restoration
financial
fraud
detection
edit
deep
learning
successfully
applied
financial
fraud
detection
tax
evasion
detection
anti
money
laundering
military
edit
united
states
department
defense
applied
deep
learning
train
robots
new
tasks
observation
partial
differential
equations
edit
physics
informed
neural
networks
used
solve
partial
differential
equations
forward
inverse
problems
data
driven
manner
one
example
reconstructing
fluid
flow
governed
navier
stokes
equations
using
physics
informed
neural
networks
require
often
expensive
mesh
generation
conventional
cfd
methods
relies
relation
human
cognitive
brain
development
edit
deep
learning
closely
related
class
theories
brain
development
specifically
neocortical
development
proposed
cognitive
neuroscientists
early
developmental
theories
instantiated
computational
models
making
predecessors
deep
learning
systems
developmental
models
share
property
various
proposed
learning
dynamics
brain
e
g
wave
nerve
growth
factor
support
self
organization
somewhat
analogous
neural
networks
utilized
deep
learning
models
like
neocortex
neural
networks
employ
hierarchy
layered
filters
layer
considers
information
prior
layer
operating
environment
passes
output
possibly
original
input
layers
process
yields
self
organizing
stack
transducers
well
tuned
operating
environment
description
stated
infant
brain
seems
organize
influence
waves
called
trophic
factors
different
regions
brain
become
connected
sequentially
one
layer
tissue
maturing
another
whole
brain
mature
variety
approaches
used
investigate
plausibility
deep
learning
models
neurobiological
perspective
one
hand
several
variants
backpropagation
algorithm
proposed
order
increase
processing
realism
researchers
argued
unsupervised
forms
deep
learning
based
hierarchical
generative
models
deep
belief
networks
may
closer
biological
reality
respect
generative
neural
network
models
related
neurobiological
evidence
sampling
based
processing
cerebral
cortex
although
systematic
comparison
human
brain
organization
neuronal
encoding
deep
networks
yet
established
several
analogies
reported
example
computations
performed
deep
learning
units
could
similar
actual
neurons
neural
populations
similarly
representations
developed
deep
learning
models
similar
measured
primate
visual
system
single
unit
population
levels
commercial
activity
edit
facebook
ai
lab
performs
tasks
automatically
tagging
uploaded
pictures
names
people
google
deepmind
technologies
developed
system
capable
learning
play
atari
video
games
using
pixels
data
input
demonstrated
alphago
system
learned
game
go
well
enough
beat
professional
go
player
google
translate
uses
neural
network
translate
languages
blippar
demonstrated
mobile
augmented
reality
application
uses
deep
learning
recognize
objects
real
time
covariant
ai
launched
focuses
integrating
deep
learning
factories
researchers
university
texas
austin
ut
developed
machine
learning
framework
called
training
agent
manually
via
evaluative
reinforcement
tamer
proposed
new
methods
robots
computer
programs
learn
perform
tasks
interacting
human
instructor
first
developed
tamer
new
algorithm
called
deep
tamer
later
introduced
collaboration
u
army
research
laboratory
arl
ut
researchers
deep
tamer
used
deep
learning
provide
robot
ability
learn
new
tasks
observation
using
deep
tamer
robot
learned
task
human
trainer
watching
video
streams
observing
human
perform
task
person
robot
later
practiced
task
help
coaching
trainer
provided
feedback
good
job
bad
job
criticism
comment
edit
deep
learning
attracted
criticism
comment
cases
outside
field
computer
science
theory
edit
see
also
explainable
ai
main
criticism
concerns
lack
theory
surrounding
methods
learning
common
deep
architectures
implemented
using
well
understood
gradient
descent
however
theory
surrounding
algorithms
contrastive
divergence
less
clear
citation
needed
e
g
converge
fast
approximating
deep
learning
methods
often
looked
black
box
confirmations
done
empirically
rather
theoretically
others
point
deep
learning
looked
step
towards
realizing
strong
ai
encompassing
solution
despite
power
deep
learning
methods
still
lack
much
functionality
needed
realizing
goal
entirely
research
psychologist
gary
marcus
noted
realistically
deep
learning
part
larger
challenge
building
intelligent
machines
techniques
lack
ways
representing
causal
relationships
obvious
ways
performing
logical
inferences
also
still
long
way
integrating
abstract
knowledge
information
objects
typically
used
powerful
systems
like
watson
use
techniques
like
deep
learning
one
element
complicated
ensemble
techniques
ranging
statistical
technique
bayesian
inference
deductive
reasoning
reference
idea
artistic
sensitivity
might
inherent
relatively
low
levels
cognitive
hierarchy
published
series
graphic
representations
internal
states
deep
layers
neural
networks
attempting
discern
within
essentially
random
data
images
trained
demonstrate
visual
appeal
original
research
notice
received
well
comments
subject
time
frequently
accessed
article
guardian
website
errors
edit
deep
learning
architectures
display
problematic
behaviors
confidently
classifying
unrecognizable
images
belonging
familiar
category
ordinary
images
misclassifying
minuscule
perturbations
correctly
classified
images
goertzel
hypothesized
behaviors
due
limitations
internal
representations
limitations
would
inhibit
integration
heterogeneous
multi
component
artificial
general
intelligence
agi
architectures
issues
may
possibly
addressed
deep
learning
architectures
internally
form
states
homologous
image
grammar
decompositions
observed
entities
events
learning
grammar
visual
linguistic
training
data
would
equivalent
restricting
system
commonsense
reasoning
operates
concepts
terms
grammatical
production
rules
basic
goal
human
language
acquisition
artificial
intelligence
ai
cyber
threat
edit
deep
learning
moves
lab
world
research
experience
show
artificial
neural
networks
vulnerable
hacks
deception
identifying
patterns
systems
use
function
attackers
modify
inputs
anns
way
ann
finds
match
human
observers
would
recognize
example
attacker
make
subtle
changes
image
ann
finds
match
even
though
image
looks
human
nothing
like
search
target
manipulation
termed
adversarial
attack
researchers
used
one
ann
doctor
images
trial
error
fashion
identify
another
focal
points
thereby
generate
images
deceived
modified
images
looked
different
human
eyes
another
group
showed
printouts
doctored
images
photographed
successfully
tricked
image
classification
system
one
defense
reverse
image
search
possible
fake
image
submitted
site
tineye
find
instances
refinement
search
using
parts
image
identify
images
piece
may
taken
another
group
showed
certain
psychedelic
spectacles
could
fool
facial
recognition
system
thinking
ordinary
people
celebrities
potentially
allowing
one
person
impersonate
another
researchers
added
stickers
stop
signs
caused
ann
misclassify
anns
however
trained
detect
attempts
deception
potentially
leading
attackers
defenders
arms
race
similar
kind
already
defines
malware
defense
industry
anns
trained
defeat
ann
based
anti
malware
software
repeatedly
attacking
defense
malware
continually
altered
genetic
algorithm
tricked
anti
malware
retaining
ability
damage
target
another
group
demonstrated
certain
sounds
could
make
google
voice
command
system
open
particular
web
address
hypothesized
could
serve
stepping
stone
attacks
e
g
opening
web
page
hosting
drive
malware
data
poisoning
false
data
continually
smuggled
machine
learning
system
training
set
prevent
achieving
mastery
reliance
human
microwork
edit
section
needs
additional
citations
verification
please
help
improve
article
adding
citations
reliable
sources
unsourced
material
may
challenged
removed
find
sources
deep
learning
news
newspapers
books
scholar
jstor
april
learn
remove
template
message
deep
learning
systems
rely
training
verification
data
generated
annotated
humans
argued
media
philosophy
low
paid
clickwork
e
g
amazon
mechanical
turk
regularly
deployed
purpose
also
implicit
forms
human
microwork
often
recognized
philosopher
rainer
hlhoff
distinguishes
five
types
machinic
capture
human
microwork
generate
training
data
gamification
embedding
annotation
computation
tasks
flow
game
trapping
tracking
e
g
captchas
image
recognition
click
tracking
google
search
results
pages
exploitation
social
motivations
e
g
tagging
faces
facebook
obtain
labeled
facial
images
information
mining
e
g
leveraging
quantified
self
devices
activity
trackers
clickwork
hlhoff
argues
commercial
end
user
applications
deep
learning
facebook
face
recognition
system
need
training
data
stop
ann
trained
rather
continued
demand
human
generated
verification
data
constantly
calibrate
update
ann
purpose
facebook
introduced
feature
user
automatically
recognized
image
receive
notification
choose
whether
like
publicly
labeled
image
tell
facebook
picture
user
interface
mechanism
generate
constant
stream
verification
data
train
network
real
time
hlhoff
argues
involvement
human
users
generate
training
verification
data
typical
commercial
end
user
applications
deep
learning
systems
may
referred
human
aided
artificial
intelligence
see
also
edit
applications
artificial
intelligence
comparison
deep
learning
software
compressed
sensing
differentiable
programming
echo
state
network
list
artificial
intelligence
projects
liquid
state
machine
list
datasets
machine
learning
research
reservoir
computing
sparse
coding
references
edit
mw
parser
output
reflist
font
size
margin
bottom
em
list
style
type
decimal
mw
parser
output
reflist
references
font
size
margin
bottom
list
style
type
inherit
mw
parser
output
reflist
columns
column
width
em
mw
parser
output
reflist
columns
column
width
em
mw
parser
output
reflist
columns
margin
top
em
mw
parser
output
reflist
columns
ol
margin
top
mw
parser
output
reflist
columns
li
page
break
inside
avoid
break
inside
avoid
column
mw
parser
output
reflist
upper
alpha
list
style
type
upper
alpha
mw
parser
output
reflist
upper
roman
list
style
type
upper
roman
mw
parser
output
reflist
lower
alpha
list
style
type
lower
alpha
mw
parser
output
reflist
lower
greek
list
style
type
lower
greek
mw
parser
output
reflist
lower
roman
list
style
type
lower
roman
mw
parser
output
cite
citation
font
style
inherit
word
wrap
break
word
mw
parser
output
citation
q
quotes
mw
parser
output
citation
target
background
color
rgba
mw
parser
output
id
lock
free
mw
parser
output
citation
cs
lock
free
background
linear
gradient
transparent
transparent
url
upload
wikimedia
org
wikipedia
commons
lock
green
svg
right
em
center
px
repeat
mw
parser
output
id
lock
limited
mw
parser
output
id
lock
registration
mw
parser
output
citation
cs
lock
limited
mw
parser
output
citation
cs
lock
registration
background
linear
gradient
transparent
transparent
url
upload
wikimedia
org
wikipedia
commons
lock
gray
alt
svg
right
em
center
px
repeat
mw
parser
output
id
lock
subscription
mw
parser
output
citation
cs
lock
subscription
background
linear
gradient
transparent
transparent
url
upload
wikimedia
org
wikipedia
commons
aa
lock
red
alt
svg
right
em
center
px
repeat
mw
parser
output
cs
ws
icon
background
linear
gradient
transparent
transparent
url
upload
wikimedia
org
wikipedia
commons
c
wikisource
logo
svg
right
em
center
px
repeat
mw
parser
output
cs
code
color
inherit
background
inherit
border
none
padding
inherit
mw
parser
output
cs
hidden
error
display
none
color
mw
parser
output
cs
visible
error
color
mw
parser
output
cs
maint
display
none
color
margin
left
em
mw
parser
output
cs
format
font
size
mw
parser
output
cs
kern
left
padding
left
em
mw
parser
output
cs
kern
right
padding
right
em
mw
parser
output
citation
mw
selflink
font
weight
inherit
schulz
hannes
behnke
sven
november
deep
learning
ki
k
nstliche
intelligenz
doi
z
issn
cid
b
c
e
f
bengio
courville
vincent
p
representation
learning
review
new
perspectives
ieee
transactions
pattern
analysis
machine
intelligence
arxiv
doi
tpami
pmid
cid
b
c
e
f
g
h
schmidhuber
j
deep
learning
neural
networks
overview
neural
networks
arxiv
doi
j
neunet
pmid
cid
bengio
yoshua
lecun
yann
hinton
geoffrey
deep
learning
nature
bibcode
natur
l
doi
nature
pmid
cid
b
silva
sam
j
po
lun
hardin
joseph
c
rothenberg
daniel
physically
regularized
machine
learning
emulators
aerosol
activation
geoscientific
model
development
doi
gmd
issn
hu
j
niu
h
carrasco
j
lennox
b
arvin
f
voronoi
based
multi
robot
autonomous
exploration
unknown
environments
via
deep
reinforcement
learning
ieee
transactions
vehicular
technology
doi
tvt
cid
archived
original
retrieved
b
ciresan
meier
u
schmidhuber
j
multi
column
deep
neural
networks
image
classification
ieee
conference
computer
vision
pattern
recognition
pp
arxiv
doi
cvpr
isbn
cid
b
krizhevsky
alex
sutskever
ilya
hinton
geoffry
imagenet
classification
deep
convolutional
neural
networks
pdf
nips
neural
information
processing
systems
lake
tahoe
nevada
archived
pdf
original
retrieved
google
alphago
ai
wins
three
match
series
world
best
go
player
techcrunch
may
archived
original
june
retrieved
june
marblestone
adam
h
wayne
greg
kording
konrad
p
toward
integration
deep
learning
neuroscience
frontiers
computational
neuroscience
arxiv
bibcode
arxiv
doi
fncom
pmc
pmid
cid
olshausen
b
emergence
simple
cell
receptive
field
properties
learning
sparse
code
natural
images
nature
bibcode
natur
doi
pmid
cid
bengio
yoshua
lee
dong
hyun
bornschein
jorg
mesnard
thomas
lin
zhouhan
february
towards
biologically
plausible
deep
learning
arxiv
cs
lg
b
c
e
f
deng
l
yu
deep
learning
methods
applications
pdf
foundations
trends
signal
processing
doi
archived
pdf
original
retrieved
b
c
e
bengio
yoshua
learning
deep
architectures
ai
pdf
foundations
trends
machine
learning
citeseerx
doi
archived
original
pdf
march
retrieved
september
lecun
yann
bengio
yoshua
hinton
geoffrey
may
deep
learning
nature
bibcode
natur
l
doi
nature
pmid
cid
shigeki
sugiyama
april
human
behavior
another
kind
consciousness
emerging
research
opportunities
emerging
research
opportunities
igi
global
isbn
bengio
yoshua
lamblin
pascal
popovici
dan
larochelle
hugo
greedy
layer
wise
training
deep
networks
pdf
advances
neural
information
processing
systems
pp
archived
pdf
original
retrieved
b
schmidhuber
j
rgen
deep
learning
scholarpedia
bibcode
schpj
doi
scholarpedia
archived
original
retrieved
b
c
hinton
g
e
deep
belief
networks
scholarpedia
bibcode
schpj
h
doi
scholarpedia
b
c
cybenko
approximations
superpositions
sigmoidal
functions
pdf
mathematics
control
signals
systems
doi
bf
cid
archived
original
pdf
october
b
c
hornik
kurt
approximation
capabilities
multilayer
feedforward
networks
neural
networks
doi
b
haykin
simon
neural
networks
comprehensive
foundation
prentice
hall
isbn
b
hassoun
mohamad
h
fundamentals
artificial
neural
networks
mit
press
p
isbn
b
lu
z
pu
h
wang
f
hu
z
wang
l
expressive
power
neural
networks
view
width
archived
wayback
machine
neural
information
processing
systems
b
c
murphy
kevin
p
august
machine
learning
probabilistic
perspective
mit
press
isbn
sonoda
sho
murata
noboru
neural
network
unbounded
activation
functions
universal
approximator
applied
computational
harmonic
analysis
arxiv
doi
j
acha
cid
hinton
g
e
srivastava
n
krizhevsky
sutskever
salakhutdinov
r
r
improving
neural
networks
preventing
co
adaptation
feature
detectors
arxiv
math
lg
bishop
christopher
pattern
recognition
machine
learning
pdf
springer
isbn
archived
pdf
original
retrieved
tappert
charles
c
father
deep
learning
international
conference
computational
science
computational
intelligence
csci
ieee
pp
doi
csci
isbn
cid
retrieved
may
ivakhnenko
g
lapa
v
g
cybernetics
forecasting
techniques
american
elsevier
publishing
co
isbn
b
ivakhnenko
alexey
polynomial
theory
complex
systems
pdf
ieee
transactions
systems
man
cybernetics
smc
doi
tsmc
archived
pdf
original
retrieved
fukushima
k
neocognitron
self
organizing
neural
network
model
mechanism
pattern
recognition
unaffected
shift
position
biol
cybern
doi
bf
pmid
cid
rina
dechter
learning
searching
constraint
satisfaction
problems
university
california
computer
science
department
cognitive
systems
laboratory
online
archived
wayback
machine
igor
aizenberg
naum
n
aizenberg
joos
p
l
vandewalle
multi
valued
universal
binary
neurons
theory
learning
applications
springer
science
business
media
co
evolving
recurrent
neurons
learn
deep
memory
pomdps
proc
gecco
washington
c
pp
acm
press
new
york
ny
usa
seppo
linnainmaa
representation
cumulative
rounding
error
algorithm
taylor
expansion
local
rounding
errors
master
thesis
finnish
univ
helsinki
griewank
andreas
invented
reverse
mode
differentiation
pdf
documenta
mathematica
extra
volume
ismp
archived
original
pdf
july
retrieved
june
werbos
p
beyond
regression
new
tools
prediction
analysis
behavioral
sciences
harvard
university
retrieved
june
werbos
paul
applications
advances
nonlinear
sensitivity
analysis
pdf
system
modeling
optimization
springer
pp
b
lecun
et
al
backpropagation
applied
handwritten
zip
code
recognition
neural
computation
pp
de
carvalho
andre
c
l
f
fairhurst
mike
c
bisset
david
august
integrated
boolean
neural
network
pattern
classification
pattern
recognition
letters
bibcode
parel
doi
hinton
geoffrey
e
dayan
peter
frey
brendan
j
neal
radford
may
wake
sleep
algorithm
unsupervised
neural
networks
science
bibcode
sci
h
doi
science
pmid
b
hochreiter
untersuchungen
zu
dynamischen
neuronalen
netzen
archived
wayback
machine
diploma
thesis
institut
f
informatik
technische
univ
munich
advisor
j
schmidhuber
hochreiter
et
al
january
gradient
flow
recurrent
nets
difficulty
learning
long
term
dependencies
kolen
john
f
kremer
stefan
c
eds
field
guide
dynamical
recurrent
networks
john
wiley
sons
isbn
behnke
sven
hierarchical
neural
networks
image
interpretation
lecture
notes
computer
science
doi
b
isbn
issn
cid
archived
original
retrieved
morgan
nelson
bourlard
herv
renals
steve
cohen
michael
franco
horacio
august
hybrid
neural
network
hidden
markov
model
systems
continuous
speech
recognition
international
journal
pattern
recognition
artificial
intelligence
doi
issn
robinson
real
time
recurrent
error
propagation
network
word
recognition
system
icassp
icassp
isbn
archived
original
retrieved
waibel
hanazawa
hinton
g
shikano
k
lang
k
j
march
phoneme
recognition
using
time
delay
neural
networks
pdf
ieee
transactions
acoustics
speech
signal
processing
doi
hdl
dmlcz
issn
archived
pdf
original
retrieved
baker
j
deng
li
glass
jim
khudanpur
lee
c
h
morgan
n
shaughnessy
research
developments
directions
speech
recognition
understanding
part
ieee
signal
processing
magazine
bibcode
ispm
b
doi
msp
hdl
cid
bengio
artificial
neural
networks
application
speech
sequence
recognition
mcgill
university
ph
thesis
archived
original
retrieved
deng
l
hassanein
k
elmasry
analysis
correlation
structure
neural
predictive
model
applications
speech
recognition
neural
networks
doi
doddington
g
przybocki
martin
reynolds
nist
speaker
recognition
evaluation
overview
methodology
systems
results
perspective
speech
communication
doi
b
heck
l
konig
sonmez
weintraub
robustness
telephone
handset
distortion
speaker
recognition
discriminative
feature
design
speech
communication
doi
acoustic
modeling
deep
neural
networks
using
raw
time
signal
lvcsr
pdf
download
available
researchgate
archived
original
may
retrieved
june
b
c
hochreiter
sepp
schmidhuber
j
rgen
november
long
short
term
memory
neural
computation
doi
neco
issn
pmid
cid
b
graves
alex
eck
douglas
beringer
nicole
schmidhuber
j
rgen
biologically
plausible
speech
recognition
lstm
neural
nets
pdf
st
intl
workshop
biologically
inspired
approaches
advanced
information
technology
bio
adit
lausanne
switzerland
pp
archived
pdf
original
retrieved
b
graves
alex
fern
ndez
santiago
gomez
faustino
connectionist
temporal
classification
labelling
unsegmented
sequence
data
recurrent
neural
networks
proceedings
international
conference
machine
learning
icml
citeseerx
santiago
fernandez
alex
graves
j
rgen
schmidhuber
application
recurrent
neural
networks
discriminative
keyword
spotting
archived
wayback
machine
proceedings
icann
pp
b
sak
ha
im
senior
andrew
rao
kanishka
beaufays
fran
oise
schalkwyk
johan
september
google
voice
search
faster
accurate
archived
original
retrieved
hinton
geoffrey
e
october
learning
multiple
layers
representation
trends
cognitive
sciences
doi
j
tics
issn
pmid
cid
archived
original
october
retrieved
june
hinton
g
e
osindero
teh
w
fast
learning
algorithm
deep
belief
nets
pdf
neural
computation
doi
neco
pmid
cid
archived
pdf
original
retrieved
bengio
yoshua
practical
recommendations
gradient
based
training
deep
architectures
arxiv
cs
lg
g
e
hinton
learning
multiple
layers
representation
archived
wayback
machine
trends
cognitive
sciences
pp
b
c
hinton
g
deng
l
yu
dahl
g
mohamed
jaitly
n
senior
vanhoucke
v
nguyen
p
sainath
kingsbury
b
deep
neural
networks
acoustic
modeling
speech
recognition
shared
views
four
research
groups
ieee
signal
processing
magazine
bibcode
ispm
h
doi
msp
cid
deng
li
hinton
geoffrey
kingsbury
brian
may
new
types
deep
neural
network
learning
speech
recognition
related
applications
overview
microsoft
research
citeseerx
archived
original
february
retrieved
february
via
research
microsoft
com
deng
li
li
jinyu
huang
jui
ting
yao
kaisheng
yu
dong
seide
frank
seltzer
michael
zweig
geoff
xiaodong
williams
jason
gong
yifan
acero
alex
recent
advances
deep
learning
speech
research
microsoft
ieee
international
conference
acoustics
speech
signal
processing
pp
doi
icassp
isbn
cid
singh
premjeet
saha
goutam
sahidullah
md
non
linear
frequency
warping
using
constant
q
transformation
speech
emotion
recognition
international
conference
computer
communication
informatics
iccci
pp
arxiv
doi
iccci
isbn
cid
sak
hasim
senior
andrew
beaufays
francoise
long
short
term
memory
recurrent
neural
network
architectures
large
scale
acoustic
modeling
pdf
archived
original
pdf
april
li
xiangang
wu
xihong
constructing
long
short
term
memory
based
deep
recurrent
neural
networks
large
vocabulary
speech
recognition
arxiv
cs
cl
zen
heiga
sak
hasim
unidirectional
long
short
term
memory
recurrent
neural
network
recurrent
output
layer
low
latency
speech
synthesis
pdf
google
com
icassp
pp
archived
pdf
original
retrieved
deng
l
abdel
hamid
yu
deep
convolutional
neural
network
using
heterogeneous
pooling
trading
acoustic
invariance
phonetic
confusion
pdf
google
com
icassp
archived
pdf
original
retrieved
b
sainath
tara
n
mohamed
abdel
rahman
kingsbury
brian
ramabhadran
bhuvana
deep
convolutional
neural
networks
lvcsr
ieee
international
conference
acoustics
speech
signal
processing
pp
doi
icassp
isbn
cid
yann
lecun
slides
deep
learning
online
archived
wayback
machine
b
c
nips
workshop
deep
learning
speech
recognition
related
applications
whistler
bc
canada
dec
organizers
li
deng
geoff
hinton
yu
b
keynote
talk
recent
developments
deep
neural
networks
icassp
geoff
hinton
yu
l
deng
g
li
f
seide
discriminative
pretraining
deep
neural
networks
u
patent
filing
b
c
deng
l
hinton
g
kingsbury
b
new
types
deep
neural
network
learning
speech
recognition
related
applications
overview
icassp
pdf
archived
pdf
original
retrieved
cite
journal
cite
journal
requires
journal
help
b
c
yu
deng
l
automatic
speech
recognition
deep
learning
approach
publisher
springer
isbn
deng
receives
prestigious
ieee
technical
achievement
award
microsoft
research
microsoft
research
december
archived
original
march
retrieved
march
b
li
deng
september
keynote
talk
achievements
challenges
deep
learning
speech
analysis
recognition
language
multimodal
processing
interspeech
archived
original
retrieved
yu
deng
l
roles
pre
training
fine
tuning
context
dependent
dbn
hmms
real
world
speech
recognition
nips
workshop
deep
learning
unsupervised
feature
learning
archived
original
retrieved
seide
f
li
g
yu
conversational
speech
transcription
using
context
dependent
deep
neural
networks
interspeech
doi
interspeech
archived
original
retrieved
deng
li
li
jinyu
huang
jui
ting
yao
kaisheng
yu
dong
seide
frank
seltzer
mike
zweig
geoff
xiaodong
may
recent
advances
deep
learning
speech
research
microsoft
microsoft
research
archived
original
october
retrieved
june
nvidia
ceo
bets
big
deep
learning
vr
venture
beat
april
archived
original
november
retrieved
april
working
neural
networking
economist
archived
original
retrieved
b
oh
k
jung
k
gpu
implementation
neural
networks
pattern
recognition
bibcode
patre
doi
j
patcog
survey
techniques
optimizing
deep
learning
gpus
archived
wayback
machine
mittal
vaishay
journal
systems
architecture
b
chellapilla
kumar
puri
sidd
simard
patrice
high
performance
convolutional
neural
networks
document
processing
archived
original
retrieved
cire
dan
claudiu
meier
ueli
gambardella
luca
maria
schmidhuber
j
rgen
september
deep
big
simple
neural
nets
handwritten
digit
recognition
neural
computation
arxiv
doi
neco
issn
pmid
cid
raina
rajat
madhavan
anand
ng
andrew
large
scale
deep
unsupervised
learning
using
graphics
processors
proceedings
th
annual
international
conference
machine
learning
icml
new
york
ny
usa
acm
citeseerx
doi
isbn
cid
sze
vivienne
chen
yu
hsin
yang
tien
ju
emer
joel
efficient
processing
deep
neural
networks
tutorial
survey
arxiv
cs
cv
b
merck
molecular
activity
challenge
kaggle
com
archived
original
retrieved
b
multi
task
neural
networks
qsar
predictions
data
science
association
www
datascienceassn
org
archived
original
april
retrieved
june
b
toxicology
st
century
data
challenge
b
ncats
announces
tox
data
challenge
winners
archived
original
retrieved
b
archived
copy
archived
original
february
retrieved
march
cite
web
cs
maint
archived
copy
title
link
ciresan
c
meier
u
masci
j
gambardella
l
schmidhuber
j
flexible
high
performance
convolutional
neural
networks
image
classification
pdf
international
joint
conference
artificial
intelligence
doi
ijcai
archived
pdf
original
retrieved
ciresan
dan
giusti
alessandro
gambardella
luca
schmidhuber
juergen
pereira
f
burges
c
j
c
bottou
l
weinberger
k
q
eds
advances
neural
information
processing
systems
pdf
curran
associates
inc
pp
archived
pdf
original
retrieved
ciresan
giusti
gambardella
l
schmidhuber
j
mitosis
detection
breast
cancer
histology
images
using
deep
neural
networks
proceedings
miccai
lecture
notes
computer
science
pt
doi
isbn
pmid
vinyals
oriol
toshev
alexander
bengio
samy
erhan
dumitru
show
tell
neural
image
caption
generator
arxiv
cs
cv
fang
hao
gupta
saurabh
iandola
forrest
srivastava
rupesh
deng
li
doll
r
piotr
gao
jianfeng
xiaodong
mitchell
margaret
platt
john
c
lawrence
zitnick
c
zweig
geoffrey
captions
visual
concepts
back
arxiv
cs
cv
kiros
ryan
salakhutdinov
ruslan
zemel
richard
unifying
visual
semantic
embeddings
multimodal
neural
language
models
arxiv
cs
lg
zhong
sheng
hua
liu
yan
liu
yang
bilinear
deep
learning
image
classification
proceedings
th
acm
international
conference
multimedia
mm
new
york
ny
usa
acm
doi
hdl
isbn
cid
deep
learning
suddenly
changing
life
fortune
archived
original
april
retrieved
april
jayashree
j
detection
diabetic
retinopathy
using
principal
component
analysis
deep
neural
networks
pdf
united
international
journal
research
technology
uijrt
silver
david
huang
aja
maddison
chris
j
guez
arthur
sifre
laurent
driessche
george
van
den
schrittwieser
julian
antonoglou
ioannis
panneershelvam
veda
january
mastering
game
go
deep
neural
networks
tree
search
nature
bibcode
natur
doi
nature
issn
pmid
cid
guide
deep
learning
neural
networks
archived
original
retrieved
szegedy
christian
toshev
alexander
erhan
dumitru
deep
neural
networks
object
detection
advances
neural
information
processing
systems
archived
original
retrieved
rolnick
david
tegmark
max
power
deeper
networks
expressing
natural
functions
international
conference
learning
representations
iclr
archived
original
retrieved
hof
robert
artificial
intelligence
finally
coming
mit
technology
review
archived
original
march
retrieved
july
b
gers
felix
schmidhuber
j
rgen
lstm
recurrent
networks
learn
simple
context
free
context
sensitive
languages
ieee
transactions
neural
networks
doi
pmid
archived
original
retrieved
b
c
sutskever
l
vinyals
le
q
sequence
sequence
learning
neural
networks
pdf
proc
nips
arxiv
bibcode
arxiv
archived
pdf
original
retrieved
b
jozefowicz
rafal
vinyals
oriol
schuster
mike
shazeer
noam
wu
yonghui
exploring
limits
language
modeling
arxiv
cs
cl
b
gillick
dan
brunk
cliff
vinyals
oriol
subramanya
amarnag
multilingual
language
processing
bytes
arxiv
cs
cl
mikolov
et
al
recurrent
neural
network
based
language
model
pdf
interspeech
doi
interspeech
archived
pdf
original
retrieved
b
learning
precise
timing
lstm
recurrent
networks
pdf
download
available
researchgate
archived
original
may
retrieved
june
lecun
et
al
gradient
based
learning
applied
document
recognition
proceedings
ieee
doi
bengio
yoshua
boulanger
lewandowski
nicolas
pascanu
razvan
advances
optimizing
recurrent
networks
ieee
international
conference
acoustics
speech
signal
processing
pp
arxiv
citeseerx
doi
icassp
isbn
cid
dahl
g
et
al
improving
dnns
lvcsr
using
rectified
linear
units
dropout
pdf
icassp
archived
pdf
original
retrieved
data
augmentation
deeplearning
ai
coursera
coursera
archived
original
december
retrieved
november
hinton
g
e
practical
guide
training
restricted
boltzmann
machines
tech
rep
utml
tr
archived
original
retrieved
yang
bulu
ayd
n
demmel
james
november
scaling
deep
learning
gpu
knights
landing
clusters
proceedings
international
conference
high
performance
computing
networking
storage
analysis
sc
sc
acm
pp
doi
isbn
cid
archived
original
july
retrieved
march
viebke
andr
memeti
suejb
pllana
sabri
abraham
ajith
chaos
parallelization
scheme
training
convolutional
neural
networks
intel
xeon
phi
journal
supercomputing
arxiv
bibcode
arxiv
v
doi
x
cid
ting
qin
et
al
learning
algorithm
cmac
based
rls
neural
processing
letters
ting
qin
et
al
continuous
cmac
qrls
systolic
array
archived
wayback
machine
neural
processing
letters
research
ai
october
deep
neural
networks
acoustic
modeling
speech
recognition
airesearch
com
archived
original
february
retrieved
october
gpus
continue
dominate
ai
accelerator
market
informationweek
december
archived
original
june
retrieved
june
ray
tiernan
ai
changing
entire
nature
computation
zdnet
archived
original
may
retrieved
june
ai
compute
openai
may
archived
original
june
retrieved
june
timit
acoustic
phonetic
continuous
speech
corpus
linguistic
data
consortium
philadelphia
robinson
tony
september
several
improvements
recurrent
error
propagation
network
phone
recognition
system
cambridge
university
engineering
department
technical
report
cued
f
infeng
tr
doi
rg
abdel
hamid
et
al
convolutional
neural
networks
speech
recognition
ieee
acm
transactions
audio
speech
language
processing
doi
taslp
cid
archived
original
retrieved
deng
l
platt
j
ensemble
deep
learning
speech
recognition
proc
interspeech
cid
th
laszl
phone
recognition
hierarchical
convolutional
deep
maxout
networks
pdf
eurasip
journal
audio
speech
music
processing
doi
cid
archived
pdf
original
retrieved
mcmillan
robert
december
skype
used
ai
build
amazing
new
language
translator
wired
wired
archived
original
june
retrieved
june
hannun
awni
case
carl
casper
jared
catanzaro
bryan
diamos
greg
elsen
erich
prenger
ryan
satheesh
sanjeev
sengupta
shubho
coates
adam
ng
andrew
deep
speech
scaling
end
end
speech
recognition
arxiv
cs
cl
mnist
handwritten
digit
database
yann
lecun
corinna
cortes
chris
burges
yann
lecun
com
archived
original
retrieved
cire
dan
meier
ueli
masci
jonathan
schmidhuber
j
rgen
august
multi
column
deep
neural
network
traffic
sign
classification
neural
networks
selected
papers
ijcnn
citeseerx
doi
j
neunet
pmid
nvidia
demos
car
computer
trained
deep
learning
january
david
talbot
mit
technology
review
g
w
smith
frederic
fol
leymarie
april
machine
artist
introduction
arts
doi
arts
blaise
ag
era
arcas
september
art
age
machine
intelligence
arts
doi
arts
goldberg
yoav
levy
omar
word
vec
explained
deriving
mikolov
et
al
negative
sampling
word
embedding
method
arxiv
cs
cl
b
socher
richard
manning
christopher
deep
learning
nlp
pdf
archived
pdf
original
july
retrieved
october
socher
richard
bauer
john
manning
christopher
ng
andrew
parsing
compositional
vector
grammars
pdf
proceedings
acl
conference
archived
pdf
original
retrieved
socher
richard
recursive
deep
models
semantic
compositionality
sentiment
treebank
pdf
archived
pdf
original
retrieved
cite
journal
cite
journal
requires
journal
help
shen
yelong
xiaodong
gao
jianfeng
deng
li
mesnil
gregoire
november
latent
semantic
model
convolutional
pooling
structure
information
retrieval
microsoft
research
archived
original
october
retrieved
june
huang
po
sen
xiaodong
gao
jianfeng
deng
li
acero
alex
heck
larry
october
learning
deep
structured
semantic
models
web
search
using
clickthrough
data
microsoft
research
archived
original
october
retrieved
june
mesnil
g
dauphin
yao
k
bengio
deng
l
hakkani
tur
x
heck
l
tur
g
yu
zweig
g
using
recurrent
neural
networks
slot
filling
spoken
language
understanding
ieee
transactions
audio
speech
language
processing
doi
taslp
cid
b
gao
jianfeng
xiaodong
yih
scott
wen
tau
deng
li
june
learning
continuous
phrase
representations
translation
modeling
microsoft
research
archived
original
october
retrieved
june
brocardo
marcelo
luiz
traore
issa
woungang
isaac
obaidat
mohammad
authorship
verification
using
deep
belief
network
systems
international
journal
communication
systems
e
doi
dac
deep
learning
natural
language
processing
theory
practice
cikm
tutorial
microsoft
research
microsoft
research
archived
original
march
retrieved
june
turovsky
barak
november
found
translation
accurate
fluent
sentences
google
translate
keyword
google
blog
archived
original
april
retrieved
march
b
c
schuster
mike
johnson
melvin
thorat
nikhil
november
zero
shot
translation
google
multilingual
neural
machine
translation
system
google
research
blog
archived
original
july
retrieved
march
sepp
hochreiter
j
rgen
schmidhuber
long
short
term
memory
neural
computation
doi
neco
pmid
cid
archived
original
retrieved
felix
gers
j
rgen
schmidhuber
fred
cummins
learning
forget
continual
prediction
lstm
neural
computation
citeseerx
doi
pmid
cid
wu
yonghui
schuster
mike
chen
zhifeng
le
quoc
v
norouzi
mohammad
macherey
wolfgang
krikun
maxim
cao
yuan
gao
qin
macherey
klaus
klingner
jeff
shah
apurva
johnson
melvin
liu
xiaobing
kaiser
ukasz
gouws
stephan
kato
yoshikiyo
kudo
taku
kazawa
hideto
stevens
keith
kurian
george
patil
nishant
wang
wei
young
cliff
smith
jason
riesa
jason
rudnick
alex
vinyals
oriol
corrado
greg
et
al
google
neural
machine
translation
system
bridging
gap
human
machine
translation
arxiv
cs
cl
metz
cade
september
infusion
ai
makes
google
translate
powerful
ever
wired
archived
original
november
retrieved
october
b
boitet
christian
blanchon
herv
seligman
mark
bellynck
val
rie
mt
web
pdf
archived
original
pdf
march
retrieved
december
arrowsmith
j
miller
p
trial
watch
phase
ii
phase
iii
attrition
rates
nature
reviews
drug
discovery
doi
nrd
pmid
cid
verbist
b
klambauer
g
vervoort
l
talloen
w
qstar
consortium
shkedy
z
thas
bender
g
hlmann
h
w
hochreiter
using
transcriptomics
guide
lead
optimization
drug
discovery
projects
lessons
learned
qstar
project
drug
discovery
today
doi
j
drudis
pmid
wallach
izhar
dzamba
michael
heifets
abraham
october
atomnet
deep
convolutional
neural
network
bioactivity
prediction
structure
based
drug
discovery
arxiv
cs
lg
toronto
startup
faster
way
discover
effective
medicines
globe
mail
archived
original
october
retrieved
november
startup
harnesses
supercomputers
seek
cures
kqed
future
archived
original
december
retrieved
november
toronto
startup
faster
way
discover
effective
medicines
globe
mail
archived
original
retrieved
gilmer
justin
schoenholz
samuel
riley
patrick
f
vinyals
oriol
dahl
george
e
neural
message
passing
quantum
chemistry
arxiv
cs
lg
zhavoronkov
alex
deep
learning
enables
rapid
identification
potent
ddr
kinase
inhibitors
nature
biotechnology
doi
x
pmid
cid
gregory
barber
molecule
designed
ai
exhibits
druglike
qualities
wired
archived
original
retrieved
reichstein
markus
camps
valls
gustau
stevens
bjorn
jung
martin
denzler
joachim
carvalhais
nuno
prabhat
february
deep
learning
process
understanding
data
driven
earth
system
science
nature
doi
issn
silva
j
heald
c
l
ravela
mammarella
munger
j
w
deep
learning
parameterization
ozone
dry
deposition
velocities
geophysical
research
letters
doi
gl
issn
rasp
stephan
pritchard
michael
gentine
pierre
deep
learning
represent
subgrid
processes
climate
models
proceedings
national
academy
sciences
doi
pnas
issn
pmc
pmid
geiss
andrew
hardin
joseph
c
december
radar
super
resolution
using
deep
convolutional
neural
network
journal
atmospheric
oceanic
technology
doi
jtech
issn
barnes
elizabeth
toms
benjamin
hurrell
james
w
ebert
uphoff
imme
anderson
chuck
anderson
david
september
indicator
patterns
forced
change
learned
artificial
neural
network
journal
advances
modeling
earth
systems
doi
ms
issn
tkachenko
yegor
april
autonomous
crm
control
via
clv
approximation
deep
reinforcement
learning
discrete
continuous
action
space
arxiv
cs
lg
van
den
oord
aaron
dieleman
sander
schrauwen
benjamin
burges
c
j
c
bottou
l
welling
ghahramani
z
weinberger
k
q
eds
advances
neural
information
processing
systems
pdf
curran
associates
inc
pp
archived
pdf
original
retrieved
feng
x
zhang
h
ren
j
shang
p
h
zhu
liang
c
guan
r
c
xu
deep
learning
based
recommender
system
pubmender
choosing
biomedical
publication
venue
development
validation
study
journal
medical
internet
research
e
doi
pmc
pmid
elkahky
ali
mamdouh
song
yang
xiaodong
may
multi
view
deep
learning
approach
cross
domain
user
modeling
recommendation
systems
microsoft
research
archived
original
january
retrieved
june
chicco
davide
sadowski
peter
baldi
pierre
january
deep
autoencoder
neural
networks
gene
ontology
annotation
predictions
proceedings
th
acm
conference
bioinformatics
computational
biology
health
informatics
bcb
acm
pp
doi
hdl
isbn
cid
archived
original
may
retrieved
november
sathyanarayana
aarti
january
sleep
quality
prediction
wearable
data
using
deep
learning
jmir
mhealth
uhealth
e
doi
mhealth
pmc
pmid
cid
choi
edward
schuetz
andy
stewart
walter
f
sun
jimeng
august
using
recurrent
neural
network
models
early
detection
heart
failure
onset
journal
american
medical
informatics
association
doi
jamia
ocw
issn
pmc
pmid
litjens
geert
kooi
thijs
bejnordi
babak
ehteshami
setio
arnaud
arindra
adiyoso
ciompi
francesco
ghafoorian
mohsen
van
der
laak
jeroen
w
van
ginneken
bram
nchez
clara
december
survey
deep
learning
medical
image
analysis
medical
image
analysis
arxiv
bibcode
arxiv
l
doi
j
media
pmid
cid
forslid
gustav
wieslander
hakan
bengtsson
ewert
wahlby
carolina
hirsch
jan
michael
stark
christina
runow
sadanandan
sajith
kecheril
deep
convolutional
neural
networks
detecting
cellular
changes
due
malignancy
ieee
international
conference
computer
vision
workshops
iccvw
pp
doi
iccvw
isbn
cid
archived
original
retrieved
de
shaunak
maity
abhishek
goel
vritti
shitole
sanjay
bhattacharya
avik
predicting
popularity
instagram
posts
lifestyle
magazine
using
deep
learning
nd
international
conference
communication
systems
computing
applications
cscita
pp
doi
cscita
isbn
cid
colorizing
restoring
old
images
deep
learning
floydhub
blog
november
archived
original
october
retrieved
october
schmidt
uwe
roth
stefan
shrinkage
fields
effective
image
restoration
pdf
computer
vision
pattern
recognition
cvpr
ieee
conference
archived
pdf
original
retrieved
kleanthous
christos
chatzis
sotirios
gated
mixture
variational
autoencoders
value
added
tax
audit
case
selection
knowledge
based
systems
doi
j
knosys
cid
czech
tomasz
deep
learning
next
frontier
money
laundering
detection
global
banking
finance
review
archived
original
retrieved
b
c
army
researchers
develop
new
algorithms
train
robots
eurekalert
archived
original
august
retrieved
august
raissi
perdikaris
p
karniadakis
g
e
physics
informed
neural
networks
deep
learning
framework
solving
forward
inverse
problems
involving
nonlinear
partial
differential
equations
journal
computational
physics
bibcode
jcoph
r
doi
j
jcp
issn
osti
cid
mao
zhiping
jagtap
ameya
karniadakis
george
em
physics
informed
neural
networks
high
speed
flows
computer
methods
applied
mechanics
engineering
bibcode
cmame
k
doi
j
cma
issn
cid
raissi
maziar
yazdani
alireza
karniadakis
george
em
hidden
fluid
mechanics
learning
velocity
pressure
fields
flow
visualizations
science
bibcode
sci
r
doi
science
aaw
pmc
pmid
utgoff
p
e
stracuzzi
j
many
layered
learning
neural
computation
doi
pmid
cid
elman
jeffrey
l
rethinking
innateness
connectionist
perspective
development
mit
press
isbn
shrager
j
johnson
mh
dynamic
plasticity
influences
emergence
function
simple
cortical
array
neural
networks
doi
pmid
quartz
sr
sejnowski
tj
neural
basis
cognitive
development
constructivist
manifesto
behavioral
brain
sciences
citeseerx
doi
x
pmid
cid
blakeslee
brain
early
growth
timetable
may
critical
new
york
times
science
section
pp
b
b
mazzoni
p
andersen
r
jordan
may
biologically
plausible
learning
rule
neural
networks
proceedings
national
academy
sciences
bibcode
pnas
doi
pnas
issn
pmc
pmid
reilly
randall
c
july
biologically
plausible
error
driven
learning
using
local
activation
differences
generalized
recirculation
algorithm
neural
computation
doi
neco
issn
cid
testolin
alberto
zorzi
marco
probabilistic
models
generative
neural
networks
towards
unified
framework
modeling
normal
impaired
neurocognitive
functions
frontiers
computational
neuroscience
doi
fncom
issn
pmc
pmid
cid
testolin
alberto
stoianov
ivilin
zorzi
marco
september
letter
perception
emerges
unsupervised
deep
learning
recycling
natural
image
features
nature
human
behaviour
doi
issn
pmid
cid
buesing
lars
bill
johannes
nessler
bernhard
maass
wolfgang
november
neural
dynamics
sampling
model
stochastic
computation
recurrent
networks
spiking
neurons
plos
computational
biology
e
bibcode
plscb
e
b
doi
journal
pcbi
issn
pmc
pmid
cid
morel
danielle
singh
chandan
levy
william
b
january
linearization
excitatory
synaptic
integration
extra
cost
journal
computational
neuroscience
doi
issn
pmid
cid
cash
yuste
r
february
linear
summation
excitatory
inputs
ca
pyramidal
neurons
neuron
doi
issn
pmid
cid
olshausen
b
field
august
sparse
coding
sensory
inputs
current
opinion
neurobiology
doi
j
conb
issn
pmid
cid
yamins
daniel
l
k
dicarlo
james
j
march
using
goal
driven
deep
learning
models
understand
sensory
cortex
nature
neuroscience
doi
nn
issn
pmid
cid
zorzi
marco
testolin
alberto
february
emergentist
perspective
origin
number
sense
phil
trans
r
soc
b
doi
rstb
issn
pmc
pmid
cid
g
l
umut
van
gerven
marcel
j
july
deep
neural
networks
reveal
gradient
complexity
neural
representations
across
ventral
stream
journal
neuroscience
arxiv
doi
jneurosci
pmc
pmid
metz
c
december
facebook
deep
learning
guru
reveals
future
ai
wired
archived
original
march
retrieved
august
gibney
elizabeth
google
ai
algorithm
masters
ancient
game
go
nature
bibcode
natur
g
doi
pmid
cid
archived
original
may
retrieved
january
silver
david
huang
aja
maddison
chris
j
guez
arthur
sifre
laurent
driessche
george
van
den
schrittwieser
julian
antonoglou
ioannis
panneershelvam
veda
lanctot
marc
dieleman
sander
grewe
dominik
nham
john
kalchbrenner
nal
sutskever
ilya
lillicrap
timothy
leach
madeleine
kavukcuoglu
koray
graepel
thore
hassabis
demis
january
mastering
game
go
deep
neural
networks
tree
search
nature
bibcode
natur
doi
nature
issn
pmid
cid
google
deepmind
algorithm
uses
deep
learning
master
game
go
mit
technology
review
mit
technology
review
retrieved
january
blippar
demonstrates
new
real
time
augmented
reality
app
techcrunch
archived
original
retrieved
metz
cade
november
researchers
leave
elon
musk
lab
begin
robotics
start
new
york
times
archived
original
july
retrieved
july
bradley
knox
w
stone
peter
tamer
training
agent
manually
via
evaluative
reinforcement
th
ieee
international
conference
development
learning
doi
devlrn
isbn
cid
talk
algorithms
ai
becomes
faster
learner
governmentciomedia
com
archived
original
august
retrieved
august
marcus
gary
january
defense
skepticism
deep
learning
gary
marcus
archived
original
october
retrieved
october
knight
march
darpa
funding
projects
try
open
ai
black
boxes
mit
technology
review
archived
original
november
retrieved
november
marcus
gary
november
deep
learning
revolution
artificial
intelligence
new
yorker
archived
original
retrieved
alexander
mordvintsev
christopher
olah
mike
tyka
june
inceptionism
going
deeper
neural
networks
google
research
blog
archived
original
july
retrieved
june
alex
hern
june
yes
androids
dream
electric
sheep
guardian
archived
original
june
retrieved
june
b
c
goertzel
ben
deep
reasons
underlying
pathologies
today
deep
learning
algorithms
pdf
archived
pdf
original
retrieved
nguyen
anh
yosinski
jason
clune
jeff
deep
neural
networks
easily
fooled
high
confidence
predictions
unrecognizable
images
arxiv
cs
cv
szegedy
christian
zaremba
wojciech
sutskever
ilya
bruna
joan
erhan
dumitru
goodfellow
ian
fergus
rob
intriguing
properties
neural
networks
arxiv
cs
cv
zhu
c
mumford
stochastic
grammar
images
found
trends
comput
graph
vis
citeseerx
doi
miller
g
n
chomsky
pattern
conception
paper
conference
pattern
detection
university
michigan
eisner
jason
deep
learning
recursive
structure
grammar
induction
archived
original
retrieved
hackers
already
started
weaponize
artificial
intelligence
gizmodo
archived
original
october
retrieved
october
hackers
force
ai
make
dumb
mistakes
daily
dot
june
archived
original
october
retrieved
october
b
c
e
ai
easy
fool
needs
change
singularity
hub
october
archived
original
october
retrieved
october
gibney
elizabeth
scientist
spots
fake
videos
nature
doi
nature
archived
original
retrieved
b
c
hlhoff
rainer
november
human
aided
artificial
intelligence
run
large
computations
human
brains
toward
media
sociology
machine
learning
new
media
society
doi
issn
cid
facebook
find
face
even
tagged
wired
issn
archived
original
august
retrieved
november
reading
edit
mw
parser
output
refbegin
font
size
margin
bottom
em
mw
parser
output
refbegin
hanging
indents
ul
margin
left
mw
parser
output
refbegin
hanging
indents
ul
li
margin
left
padding
left
em
text
indent
em
mw
parser
output
refbegin
hanging
indents
ul
mw
parser
output
refbegin
hanging
indents
ul
li
list
style
none
max
width
px
mw
parser
output
refbegin
hanging
indents
ul
li
padding
left
em
text
indent
em
mw
parser
output
refbegin
columns
margin
top
em
mw
parser
output
refbegin
columns
ul
margin
top
mw
parser
output
refbegin
columns
li
page
break
inside
avoid
break
inside
avoid
column
goodfellow
ian
bengio
yoshua
courville
aaron
deep
learning
mit
press
isbn
archived
original
retrieved
introductory
textbook
cite
book
cs
maint
postscript
link
mw
parser
output
navbox
box
sizing
border
box
border
px
solid
b
width
clear
font
size
text
align
center
padding
px
margin
em
auto
mw
parser
output
navbox
navbox
margin
top
mw
parser
output
navbox
navbox
mw
parser
output
navbox
navbox
styles
navbox
margin
top
px
mw
parser
output
navbox
inner
mw
parser
output
navbox
subgroup
width
mw
parser
output
navbox
group
mw
parser
output
navbox
title
mw
parser
output
navbox
abovebelow
padding
em
em
line
height
em
text
align
center
mw
parser
output
navbox
group
white
space
nowrap
text
align
right
mw
parser
output
navbox
mw
parser
output
navbox
subgroup
background
color
fdfdfd
mw
parser
output
navbox
list
line
height
em
border
color
fdfdfd
mw
parser
output
navbox
list
group
text
align
left
border
left
width
px
border
left
style
solid
mw
parser
output
tr
tr
navbox
abovebelow
mw
parser
output
tr
tr
navbox
group
mw
parser
output
tr
tr
navbox
image
mw
parser
output
tr
tr
navbox
list
border
top
px
solid
fdfdfd
mw
parser
output
navbox
title
background
color
ccf
mw
parser
output
navbox
abovebelow
mw
parser
output
navbox
group
mw
parser
output
navbox
subgroup
navbox
title
background
color
ddf
mw
parser
output
navbox
subgroup
navbox
group
mw
parser
output
navbox
subgroup
navbox
abovebelow
background
color
e
e
ff
mw
parser
output
navbox
even
background
color
f
f
f
mw
parser
output
navbox
odd
background
color
transparent
mw
parser
output
navbox
hlist
td
dl
mw
parser
output
navbox
hlist
td
ol
mw
parser
output
navbox
hlist
td
ul
mw
parser
output
navbox
td
hlist
dl
mw
parser
output
navbox
td
hlist
ol
mw
parser
output
navbox
td
hlist
ul
padding
em
mw
parser
output
navbox
navbar
display
block
font
size
mw
parser
output
navbox
title
navbar
float
left
text
align
left
margin
right
em
v
e
differentiable
computing
general
differentiable
programming
neural
turing
machine
differentiable
neural
computer
automatic
differentiation
neuromorphic
engineering
cable
theory
pattern
recognition
computational
learning
theory
tensor
calculus
concepts
gradient
descent
sgd
clustering
regression
overfitting
adversary
attention
convolution
loss
functions
backpropagation
normalization
activation
softmax
sigmoid
rectifier
regularization
datasets
augmentation
programming
languages
python
julia
application
machine
learning
artificial
neural
network
deep
learning
scientific
computing
artificial
intelligence
hardware
ipu
tpu
vpu
memristor
spinnaker
software
library
tensorflow
pytorch
keras
theano
implementation
audio
visual
alexnet
wavenet
human
image
synthesis
hwr
ocr
speech
synthesis
speech
recognition
facial
recognition
alphafold
dall
e
verbal
word
vec
transformer
bert
nmt
project
debater
watson
gpt
gpt
decisional
alphago
alphazero
q
learning
sarsa
openai
five
self
driving
car
muzero
action
selection
robot
control
people
alex
graves
ian
goodfellow
yoshua
bengio
geoffrey
hinton
yann
lecun
andrew
ng
demis
hassabis
david
silver
fei
fei
li
organizations
deepmind
openai
mit
csail
mila
google
brain
fair
portals
computer
programming
technology
category
artificial
neural
networks
machine
learning
newpp
limit
report
parsed
mw
cached
time
cache
expiry
reduced
expiry
false
complications
vary
revision
sha
cpu
time
usage
seconds
real
time
usage
seconds
preprocessor
visited
node
count
post
expand
include
size
bytes
template
argument
size
bytes
highest
expansion
depth
expensive
parser
function
count
unstrip
recursion
depth
unstrip
post
expand
size
bytes
lua
time
usage
seconds
lua
memory
usage
bytes
lua
profile
ms
recursiveclone
ms
scribunto
luasandboxcallback
callparserfunction
ms
scribunto
luasandboxcallback
find
ms
datawrapper
ms
scribunto
luasandboxcallback
match
ms
scribunto
luasandboxcallback
gsub
ms
ms
makemessage
ms
select
one
ms
others
ms
number
wikibase
entities
loaded
transclusion
expansion
time
report
ms
calls
template
total
template
reflist
template
cite
journal
template
cite
web
template
cite
book
template
cite
arxiv
template
sidebar
collapsible
lists
template
machine
learning
template
navbox
template
differentiable
computing
saved
parser
cache
key
enwiki
pcache
idhash
canonical
timestamp
revision
id
serialized
json
retrieved
oldid
categories
deep
learning
artificial
neural
networks
artificial
intelligence
emerging
technologies
hidden
categories
webarchive
template
wayback
links
cs
long
volume
value
cs
errors
missing
periodical
cs
maint
archived
copy
title
articles
short
description
short
description
matches
wikidata
wikipedia
articles
technical
july
articles
technical
articles
unsourced
statements
articles
unsourced
statements
november
articles
unsourced
statements
july
articles
needing
additional
references
april
articles
needing
additional
references
cs
maint
postscript
articles
prone
spam
june
navigation
menu
